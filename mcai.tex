\documentclass[12pt, oneside]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage[left=1in, right=1in, top=1in, bottom=1in]{geometry}   
\linespread{1.5}
\usepackage{hyperref}             		% See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   		% ... or a4paper or a5paper or ... 
%\geometry{landscape}                		% Activate for rotated page geometry
%\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or eps§ with pdflatex; use eps in DVI mode
								% TeX will automatically convert eps --> pdf in pdflatex		
\usepackage{amssymb}

%SetFonts

%SetFonts


\title{Artificial Intelligence, Data Science Methods, and Strategic Opportunities for the Miller Center}
\author{Miles Efron}
\date{}							% Activate to display a given date or no date

\begin{document}
\maketitle

\abstract{Since the release of ChatGPT in 2022, Artificial Intelligence (AI) technologies have seized the public’s attention.  For institutions such as the Miller Center, these technologies offer opportunities to improve institutional impact and to modernize workflows. But how to capitalize on these opportunities, and how to avoid their concomitant pitfalls is not obvious.  To make sense of AI’s promises and risks, this whitepaper undertakes a wholesale consideration of how Miller Center staff and leadership could marshal AI technology (broadly understood) to further the center’s mission and work.  The whitepaper consists of three main parts.  First, we give a detailed census of the data available for AI work at the Miller Center, with an eye towards understanding how our data holdings could be brought to bear on future technological initiatives.  Second, we outline the institutional context in which future data-intensive work would take place.  This involves both a survey of relevant past work at the Miller Center, and a consideration of AI initiatives and working groups currently at work across Grounds at UVA.  Lastly, the paper concludes with a set of recommendations for future work—a listing of variously ambitious data-intensive projects that the Miller Center could undertake to increase its overall institutional impact and success.}

\pagebreak
\tableofcontents
\pagebreak



\section{Introduction}\label{section.introduction}
In 2023, Artificial Intelligence (AI) decisively stepped out of the shadows of theoretical computer science and into the limelight of practical, impactful technology. This transition was fueled by notable advancements in AI technology and an increasing ease of access to AI tools.  With AI at the front of public attention and imagination, there is a growing sense of possibility but also anxiety around AI.  AI tools support truly novel workflows, allowing people to survey and capitalize on data at previously unseen scale with ease.  But the very flexibility of these tools, their novelty and breadth of application, makes them hard to understand fully.  Exactly how to use these new tools is a non-obvious, non-trivial question.
Nowhere are these developments more keenly felt than in universities.  Academia, with its traditions of scholarly exploration, argumentation from data, and the free exchange of ideas, is uniquely situated to make use of AI.  However, the same challenges obtain in universities as anywhere else, perhaps more so—there is a sense that AI presents a singular opportunity for academia, but how to meet this opportunity is a profound challenge.  In light of this challenge, university faculty, staff, and administrators have begun to organize their thinking and efforts, forming committees, research programs, and initiatives to study how to integrate AI into their work.  2024, it seems, will be a watershed year for the fate of AI in academia.
As a scholarly unit with a huge portfolio of machine-readable data and a history of technical innovation, the Miller Center of Public Affairs at UVA is poised to find uses for AI that both increase the impact of its work and that catch the public attention.   Without any formal deliberation, Miller Center leadership and staff have already recognized that AI presents us with a chance to grow the impact of our work.  In terms of outward-facing impact, there is a sense that AI will help us share our results more broadly than before and with greater effect.  In terms of internal workflows, Miller Center scholars and staff already use AI on a daily basis (as of 2024 everyday software such as Google, MS Word, and Adobe Photoshop all use AI), and it seems unlikely for the footprint of AI on our workflows to shrink.
To help synthesize these issues and to recommend a strategic posture with respect to AI, Miller Center leadership commissioned this white paper.  The goal of the paper is twofold:

\begin{enumerate}
\item To give readers at the Miller Center a shared context (vocabulary, historical framework) for understanding what factors are in play when we discuss AI and academia in 2024.
\item To propose a slate of possible projects that would bring AI technologies to bear on Miller Center work in tangible, impactful ways.
\end{enumerate}


The paper starts with background and crucial definitions for understanding AI as it pertains to Miller Center priorities and work.  A high-level census of Miller Center data follows.  While tools such as ChatGPT are fully useable without any particular data requirement, more advanced applications of AI require data in sufficient quantity and of high quality.  The aim of the data census is to give a basis for understanding what kinds of model training or evaluation would be feasible for the Miller Center.  The final section of the paper enumerates several AI projects that the Miller Center could undertake.  Our goal in this enumeration is to offer projects of varying ambition and varying risk, from simple “low-hanging fruit” to cutting-edge deployments that would entail research activity in their own right.  Overall, our hope is to give a sense of what is possible for the Miller Center, in efforts to spark a conversation about how best to move forward.


\section{Definitions and Descriptions of Data Science and Artificial Intelligence}\label{section.definitions}
This whitepaper is concerned with how modern advances in computing can be brought to bear on the Miller Center’s goals and research problems.  The advances we consider occupy the space denoted by terms such as data science and artificial intelligence (AI).  In this section we offer working definitions of these terms and related vocabulary.

\subsection{Data Science}\label{section.definitions.data-science}
The School of Data Science (SDS) at UVA defines data science as “the study of data and the methods used to learn from data.” \cite{sds:2023}  In the SDS formulation, broad definition entails several more focused types of activity, including:

\begin{itemize}
\item Research and development on statistical prediction models.
\item Methods and best-practice in computing that support large-scale operations on data.
\item Advanced data visualization methods.
\item The study of how data can best impact society.
\end{itemize}

To contextualize their work, SDS explains that “Much of our research uses statistical, computational, and philosophical principles to enhance ongoing collaborations …[with other departments and fields].”  In other words, data science often plays a supporting role in the research process.  Instead of presenting a fully formed view of research in its own right, data science is essentially a set of principles and methods that allow us to use tools (statistical prediction, visualizations, etc.) in our own work in ways that have proven to yield value.


\subsection{Artificial Intelligence}\label{section.definitions.artificial-intelligence}
Though the term Artificial Intelligence (AI) was coined in the 1940’s, it took on new meaning in 2022, when OpenAI released their chatbot, ChatGPT.  What we currently call artificial intelligence is best understood as the confluence of three related developments:

\begin{itemize}
\item Cheap, plentiful computation has become pervasive.  This makes once-impossible computational problems tractable. Cloud computing and advanced networking make it simple to build heroically powerful supercomputers.
\item Electronic data is abundant and inexpensive.  The internet has reached a size and a level of professionalism in its technical underpinnings that make it feasible to acquire, store, and recall data on a scale that has never been possible before.
\item Deep learning expanded the value of machine learning. Research in machine learning has matured in a way that allows programmers to build predictive models that that solve human problems with previously unseen accuracy and flexibility.   
\end{itemize}

When people talk about AI today, they are usually talking about this trifecta, an intersection of historical events that together allow computers to do things that we recognize as wholly novel, tasks that were formerly limited to human agency.

For the remainder of this whitepaper, we will use the term \emph{artificial intelligence} to refer to the full breadth of this phenomenon.  That is, we will use AI to describe both novel inferential systems and the milieu in which they have been developed—\emph{AI, for our purposes, is the intersection of data-intensive computation, data-centric computational best practice, and the deep learning models that arise from these practices.}


\subsection{Neural Networks and Deep Learning}\label{section.definitions.deep-learning}
The term \emph{machine learning} refers to the practice of training computers to recognize patterns in order for them to make predictions or other inferences.  Machine learning is a well-established academic field, straddling computer science and statistics.  In the early 2000’s, the state of the art in machine learning suddenly and fundamentally changed, when researchers sparked a novel innovation—\emph{deep learning.}  Deep learning has become the mainstay of modern machine learning, and it forms the backbone of the current generation of AI systems.

The hallmark of deep learning is the size and structure of its models.  Earlier machine learning algorithms used training data to learn a relatively small number of model parameters.  These parameters were essentially weights, and they allowed a system to make inferences.  For instance, a classical email spam filter guessed the status (spam or non-spam) of an incoming message by observing the word tokens in the message.  The filter would look up how strongly each word is associated with spam messages versus non-spam messages.  By summing these weights over the terms in a message, the system could reasonably predict the likelihood that a person would judge the message to be spam.  In this scenario, the model consists of two weights (spamminess and non-spamminess) of each word in the English language (assuming the user is an English speaker), on the order of tens of thousands of parameters.  Different algorithms varied in how they estimated these weights.  But the basic structure of the model (a pair of weights per word type) and the operation for inference (a weighted sum) were shared by most methods.

Deep learning fundamentally changed this state of affairs.  Instead of tens of thousands of parameters, deep learning models have millions or billions, and in some cases trillions, of parameters.  As in older models, deep learning has weights analogous to those described above; in a deep learning email filter, we would indeed see weights for each word in the English language.  But in addition to these, deep learning contains armies of secondary parameters.  Collectively, these so-called “hidden layers” of the model capture relationships between observed variables such as words.  This architecture allows, for instance, a deep learning model to learn that the phrase \emph{machine learning} is a single concept, an idea greater than the sum of its lexical parts.  This novel architecture qualitatively changed the sophistication and expressiveness of machine learning models.


\subsection{Large Language Models}\label{section.definitions.llms}
Much of the hype around AI concerns so-called large language models (LLMs).  As their name suggests, LLMs are deep learning models that attempt to mimic human linguistic behavior.  OpenAI’s GPT, Google’s Bard, and Facebook’s Llama are all LLMs.  The accuracy and flexibility of LLMs is perhaps the most striking development in the landscape of current AI research and development.  Due to the Miller Center’s focus on scholarly communication and political insight, LLMs will also be of special interest as we consider how the center can make use of AI in the future.

A particularly important distinction between older models and LLMs is that LLMs are trained to perform well on a variety of linguistic tasks, while older models were narrowly scoped.  In our example above we mentioned an email spam filter.  This is a classic example of older-generation machine learning.  Such a filter is intended to be used in a narrow setting, for a single task.  On the other hand, LLMs like GPT or Llama model general linguistic fluency.  They can perform well on a variety of loosely structured tasks such as summarization, translation, or even writing from scratch.  In fact, an interesting result of modern AI is that researchers often do not know what tasks their models will do well on, and an import goal of current research is finding and demonstrating novel uses of LLMs.  This is likely to be a part of the work we at the Miller Center undertake as we explore AI suitability for our needs.

This new-found model fluency and flexibility is partly due to the novel model structure afforded by deep learning.  Without deep learning’s vast architectural complexity, LLM’s would be unable to encode human knowledge so accurately.  But the other crucial factor in this development is an abundance of training data.  Older models, with parsimonious structures, could be trained with relatively small sets of data.  LLMs, on the other hand, require terabytes, even petabytes of data before they can perform well.  Figure 1 shows the growth of LLM parameter spaces between 2018 and 2023\footnote{Information about the evolution of model size is available in several sources in this paper’s Related Reading section, such as \cite{shazeer:2017, wei:2022}, Lepkin at al. (2021) and Wei et al. (2022).}.  Early models such as GPT-1 learned on the order of 100 million parameters, while the current state of the art (e.g. GPT4) boasts over 100 trillion parameters.  This increase has improved the accuracy and fluency of LLMs.  But increasing model size demands a corresponding increase in training data.  Training data on the order of 10 terabytes was common in 2015.  But current models demand multiple petabytes to reach a stable, saturated status.  Because these models require so much data to reach their potential, they are expensive to build, and an important fact of modern AI work is that instead of training new models for each deployment, it is incumbent on AI professionals to find creative ways to re-use pre-trained models.

\begin{figure}[htbp]
\begin{center}
\includegraphics{./figures/llm_params.png}
\caption{Large Language Models, 2012-2023.}
\label{default}
\end{center}
\end{figure}


\subsection{Foundation Models, Model Fine-Tunings and Retrieval-Augmented Generation}\label{section.definitions.foundation-models}

\pagebreak
\bibliographystyle{apalike}
\bibliography{mcai}

\end{document}  