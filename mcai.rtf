{\rtf1\ansi\ansicpg1252\cocoartf2709
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\froman\fcharset0 TimesNewRomanPS-BoldMT;\f1\froman\fcharset0 TimesNewRomanPSMT;\f2\froman\fcharset0 TimesNewRomanPS-ItalicMT;
\f3\fmodern\fcharset0 CourierNewPSMT;\f4\fmodern\fcharset0 CourierNewPS-ItalicMT;\f5\fmodern\fcharset0 CourierNewPS-BoldMT;
}
{\colortbl;\red255\green255\blue255;\red191\green191\blue191;}
{\*\expandedcolortbl;;\csgray\c79525;}
{\info
{\title Original file was mcai.tex}
{\doccomm Created using latex2rtf 2.3.18 r1267 (released May 30, 2020) on Tue Feb 13 16:59:38 2024}}\paperw12280\paperh15900\margl1084\margr1084\margb1445\margt1445\vieww16940\viewh9660\viewkind0
\deftab720
\pard\pardeftab720\sb240\sa240\qc\partightenfactor0

\f0\b\fs36 \cf0 Artificial Intelligence and Strategic Opportunities for the Miller Center\
\pard\pardeftab720\fi360\sa120\qc\partightenfactor0

\f1\b0\fs24 \cf0 Miles Efron\
 Miller Center of Public Affairs \
\pard\pardeftab720\sa120\qc\partightenfactor0
\cf0 University of Virginia \
mefron@virginia.edu \
\
\pard\pardeftab720\sb240\sa120\qc\partightenfactor0
\cf0  \
\pard\pardeftab720\qj\partightenfactor0
\cf0 \
\page \pard\pardeftab720\sb300\sa120\partightenfactor0

\f0\b\fs32 \cf0 1  Executive Summary\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 Since the release of ChatGPT in 2022, Artificial Intelligence (AI) technologies have seized the public\'92s attention. For institutions such as the Miller Center, these technologies offer opportunities to improve institutional impact and to modernize workflows. But how to capitalize on these opportunities, and how to avoid their pitfalls is not obvious. To make sense of AI's promises and risks, this white paper undertakes a wholesale consideration of how Miller Center leadership could marshal AI technology to further the center's mission and work. \
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 The paper consists of four main parts. First we develop a vocabulary for discussing AI, outlining key terms and functionalities that form our shared vocabulary for talking about AI. Data is the coin of the realm in AI, driving what is possible and how we implement solutions. Recognizing data\'92s practical importance, Section 4 enumerates the key data sets available for AI work at the Miller Center. To give a sense of how the Miller Center fits into the larger AI landscape at UVA, Section 5 outlines UVA\'92s most vital current and recently completed AI initiatives. The remainder of the white paper enumerates seven projects that the Miller Center could undertake as an initial foray into using AI for its work. By design, these projects span a wide array of risk/reward profiles, giving leadership a sense of what is possible and a range of commitment levels to consider.\
For readers who need to understand this paper\'92s suggestions quickly, the following details will be most helpful. Figure 2 gives an overview of the Miller Center\'92s holdings in terms of textual data. This figure is vital for understanding the proposed slate of AI projects. In terms of understanding cross-Grounds AI initiatives, the two most crucial details are: \
\pard\tx283\pardeftab720\li600\fi-300\sb50\sa120\partightenfactor0
\cf0 \'95	The Futures Initiative is a university-level project that will deliver a strategic report on AI and related issues to Jim Ryan. Organizers are accepting nominations from unit leaders for membership on the Futures Initiative\'92s working groups. \
\'95	The Vice Provost for Research has recently launched a task force to assess AI research efforts across Grounds. The Miller Center has been picked for featured inclusion in the final report of this task force. \
\pard\pardeftab720\sb60\qj\partightenfactor0
\cf0 The projects listed in this paper\'92s last section are summarized in Table 1 in this executive summary. Section 6.5 gives high-level recommendations for choosing how to put AI into production at the Miller Center. \
\pard\pardeftab720\sb240\qc\partightenfactor0
\cf0  \
\pard\pardeftab720\sb120\sa120\partightenfactor0
\cf0 Table 1: A summary of AI projects proposed in this white paper. Projects are ranked in increasing order of difficulty and cost.\

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2160
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx6480
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Project\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Difficulty\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Cost\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Section\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clmgf \clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2160
\clmrg \clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clmrg \clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx6480
\clmrg \clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\qc\partightenfactor0
\cf0  Easy Projects\cell 
\pard\intbl\itap1\cell 
\pard\intbl\itap1\cell 
\pard\intbl\itap1\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2160
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx6480
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Improving mc.org site search\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 greenLow\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 greenLow\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 6.2.3\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2160
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx6480
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Informally integrating AI tools into Miller Center work\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 greenLow\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 GoldenrodMedium\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 6.2.1\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2160
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx6480
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Expanding our data portal\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 greenLow\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 GoldenrodMedium\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 6.2.2\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clmgf \clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2160
\clmrg \clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clmrg \clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx6480
\clmrg \clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\qc\partightenfactor0
\cf0 \
\pard\intbl\itap1\pardeftab720\fi360\sb120\sa120\qc\partightenfactor0
\cf0 More Ambitious Projects\cell 
\pard\intbl\itap1\cell 
\pard\intbl\itap1\cell 
\pard\intbl\itap1\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2160
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx6480
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  LLMs to extract interview and recording metadata\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 GoldenrodMedium\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 greenLow\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 6.3.3\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2160
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx6480
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Toolkit to support PRP scholarship\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 redHigh\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Goldenrodmedium\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 6.3.2\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2160
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx6480
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  A Miller Center language model (internal deployment)\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 redHigh\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 greenLow\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 6.3.1\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2160
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx6480
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  A Miller Center language model (public deployment)\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 redHigh\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 redHigh\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 6.3.1\cell \lastrow\row
\pard\pardeftab720\sb120\sa120\partightenfactor0
\cf0  \
\pard\pardeftab720\sb60\qj\partightenfactor0
\cf0 \page \pard\pardeftab720\sb480\sa120\partightenfactor0

\f0\b\fs32 \cf0 2  Introduction\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 In 2022, Artificial Intelligence (AI) decisively stepped out of the shadows of theoretical computer science and into the limelight of practical, impactful technology. This transition was fueled by notable advancements in AI technology and an increasing ease of access to AI tools. With AI at the front of public attention and imagination, there is a growing sense of possibility but also anxiety around AI. AI tools support truly novel workflows, allowing people to survey and capitalize on data at previously unseen scales. But the power of these tools and their novelty makes them hard to understand. Exactly how to use these new tools is an urgent question without obvious answers.\
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 Nowhere are these developments more keenly felt than in universities. Academia, with its traditions of scholarly exploration, argumentation from data, and the free exchange of ideas, is uniquely situated to make use of AI. However, the same challenges obtain in universities as anywhere else, perhaps more so. There is a sense that AI presents a singular opportunity for academia. But how to meet this opportunity is a profound challenge. In light of this challenge, university faculty, staff, and administrators have begun to organize their thinking and efforts, forming committees, research programs, and initiatives to study how to integrate AI into their work. 2024, it seems, will be a watershed year for the fate of AI in academia.\
As a scholarly unit with a huge portfolio of machine-readable data and a history of technical innovation, the Miller Center of Public Affairs at UVA is poised to find uses for AI that increase the impact of Miller Center work and that catch the public attention. Miller Center leadership has already recognized that AI presents a chance to increase the impact of our work. In terms of outward-facing impact, there is a sense that AI will help us share our results more broadly than we could before. In terms of internal workflows, Miller Center scholars and staff already use AI on a daily basis (as of 2024 everyday software such as Google, MS Word, and Adobe Photoshop all use AI), and it seems unlikely that AI\'92s footprint on our work will shrink.\
To help synthesize these issues and to recommend a strategic posture with respect to AI, Miller Center leadership commissioned this white paper. The goal of the paper is twofold:\
\pard\tx283\pardeftab720\li600\fi-300\sb50\sa120\partightenfactor0
\cf0 	1.	To give readers at the Miller Center a shared context (vocabulary, historical framework) for understanding what factors are in play when we discuss AI and academia in 2024.  \
\page 	2.	To propose a slate of possible projects that would bring AI technologies to bear on Miller Center work in tangible, impactful ways. \
\pard\pardeftab720\fi360\sb60\qj\partightenfactor0
\cf0 This paper starts with background and crucial definitions for understanding AI as it pertains to Miller Center priorities and work. A high-level census of Miller Center data follows. The aim of the data census is to give a basis for understanding what kinds of model training and evaluation would be feasible for the Miller Center. After a survey of high-profile AI initiatives at UVA, the final section of the paper enumerates several AI projects that the Miller Center could undertake. Our goal in this enumeration is to offer projects of varying ambition and varying risk, from simple \'93low-hanging fruit\'94 to cutting-edge deployments that would entail research activity in their own right. Overall, our hope is to give a sense of what is possible for the Miller Center, in efforts to spark a conversation about what is desirable.\
\
\pard\pardeftab720\sb240\sa120\partightenfactor0

\f0\b\fs32 \cf0 3  Definitions and Descriptions\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 To ground our discussion of AI and its application to the Miller Center\'92s work, this section offers definitions and basic vocabulary. Each of the terms listed in this section is complex and multifaceted. Our aim in defining these terms is to give all readers a shared sense of how each term fits into this paper. That is, our goal is not so much to give conclusive definitions, but instead to explain how each term will fit into the discussion presented specifically in this white paper.\
\
\pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b\fs32 \cf0 3.1  Artificial Intelligence\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 Though the term Artificial Intelligence (AI) was coined in the 1940's, it took on new meaning in recent years. AI used to refer to systems that relied on symbolic logic to mimic human inference. Now, people talking about AI are usually referring to systems that rely on massive data and statistical models to mimic human creativity. What we currently call artificial intelligence is best understood as the confluence of three related developments:\
\pard\tx283\pardeftab720\li600\fi-300\sb50\sa120\partightenfactor0
\cf0 \'95	Cheap, plentiful computation has become pervasive. This makes once-impossible computational problems tractable. Cloud computing and advanced networking make it simple to build heroically powerful supercomputers. \
\'95	Electronic data is abundant and inexpensive. The internet has reached a size and a level of professionalism in its technical underpinnings that make it feasible to acquire, store, and recall data on a scale that has never been possible before. \
\'95	Deep learning expanded the power of machine learning. Research in machine learning has matured in a way that allows programmers to build predictive models that that solve human problems with previously unseen accuracy and flexibility. \
\pard\pardeftab720\fi360\sb60\qj\partightenfactor0
\cf0 Today, discussions of AI usually concern this trifecta, an intersection of historical events that together allow computers to do things that we recognize as wholly novel, tasks that were formerly limited to human agency.\
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 For the remainder of this white paper, we will use the term 
\f2\i artificial intelligence
\f1\i0  to refer to 
\f2\i machine learning systems that use massive-scale data to approximate human skill on creative tasks such as writing, editing, and data analysis.
\f1\i0 . This definition is also sometimes called 
\f2\i generative AI
\f1\i0  because these AI systems are capable of generating novel artifacts such as texts, images, and audio recordings.\
\
\pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b\fs32 \cf0 3.2  Deep Learning\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 The term 
\f2\i machine learning
\f1\i0  refers to the practice of training computers to recognize patterns in data. Machine learning is a well-established academic field, straddling computer science and statistics. In the early 2000's, the state of the art in machine learning suddenly and fundamentally changed, when researchers sparked a novel innovation, 
\f2\i deep learning.
\f1\i0  Deep learning has become the mainstay of modern machine learning, and it forms the backbone of the current generation of AI systems.\
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 The hallmark of deep learning is the size and structure of its models. Earlier machine learning algorithms used their training data to estimate a relatively small number of model parameters. For instance, a classical email spam filter guessed the status (spam or non-spam) of an incoming message by observing the word tokens in the message. The filter would look up how strongly each word is associated with spam messages versus non-spam messages. Each word\'92s weight was a parameter of the model. By summing these weights over the terms in a message, the system could reasonably predict the likelihood that a person would judge the message to be spam. In this scenario, the model consists of two weights (spamminess and non-spamminess) for each word in the English language (assuming the user is an English speaker)\'97on the order of tens of thousands of parameters. Different algorithms varied in how they estimated these weights. But the basic structure of the model (a pair of weights per word type) and the weighted sum operation for inference were shared by most algorithms.\
Deep learning fundamentally changed this state of affairs. Instead of tens of thousands of parameters, deep learning models have millions or billions, and in some cases trillions of parameters. As in older models, deep learning has weights analogous to those described above; in a deep learning email filter, we would indeed see weights for each word in the English language. But in addition to these, deep learning contains armies of secondary parameters. Collectively, these so-called "hidden layers\'94 of the model capture relationships between observed variables such as words. For instance, this architecture allows a deep learning model to learn that the phrase 
\f2\i the Miller Center
\f1\i0  is a single concept, an idea greater than the sum of its lexical parts. This novel architecture qualitatively changed the sophistication and expressiveness of machine learning models.\
\
\pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b\fs32 \cf0 3.3  Large Language Models\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 Much of the hype around AI concerns so-called large language models (LLMs). As their name suggests, LLMs are deep learning models that attempt to mimic human linguistic behavior. OpenAI's GPT-4, Google's Gemini, and Facebook's Llama are all LLMs. The accuracy and flexibility of LLMs is perhaps the most striking development in the landscape of current AI research and development. Due to the Miller Center's focus on scholarly communication and political insight, LLMs will also be of special interest as we consider how the center can make use of AI in the future.\
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 A particularly important distinction between older models and LLMs is that LLMs are trained to perform well on a variety of linguistic tasks, while older models were narrowly scoped. In our example above we mentioned an email spam filter. This is a classic example of older-generation machine learning. Such a filter is intended to be used in a narrow setting, for a single task\'97all it does is guess if incoming email messages are spam. On the other hand, LLMs like GPT-4 or Llama model general linguistic fluency. They can perform well on a variety of loosely structured tasks such as summarization, translation, or even writing from scratch. In fact, an interesting result of modern AI is that researchers often do not know what tasks their models will do well on, and an important research goal is finding and demonstrating novel uses of LLMs. This is likely to be a part of the work we at the Miller Center undertake as we explore AI suitability for our needs.\
This newfound model fluency and flexibility is partly due to the novel model structure afforded by deep learning. Without deep learning's vast architectural complexity, LLMs would be unable to encode human knowledge so accurately. But the other crucial factor in this development is an abundance of training data. Older models, with more parsimonious structures, could be trained with small sets of data. LLMs, on the other hand, require terabytes, even petabytes of data before they can perform well. Figure 1 shows the growth of LLM parameter spaces between 2018 and 2023. Early models such as GPT-1 learned on the order of 100 million parameters, while the current state of the art (e.g. GPT-4) boasts over 100 trillion parameters. This increase has improved the accuracy and fluency of LLMs. But increasing model size demands a corresponding increase in training data. Training data on the order of 100 gigabytes was common in 2015. But current models demand multiple terabytes to reach a stable, fully trained state. For instance, OpenAI has published results showing that their GPT-3 model required 45 terabytes (and $100M) for proper training [Brown et\'a0 al., 2020]. Because these models require so much data to reach their potential, they are expensive to build, and an important fact of modern AI work is that instead of training new models for each deployment, it is incumbent on AI professionals to find creative ways to re-use pre-trained models.\
\pard\pardeftab720\fi360\sb240\qc\partightenfactor0
\cf0  \
\pard\pardeftab720\sb120\sa120\qc\partightenfactor0
\cf0  \
\pard\pardeftab720\sb120\sa120\partightenfactor0
\cf0 Figure 1: Large language models and the sizes of their parameter space, 2018-2023.\
\pard\pardeftab720\sb360\sa120\partightenfactor0

\f0\b\fs32 \cf0 3.4  Foundation Models and Model Fine-Tuning\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 Because current LLMs are so expensive and time-consuming to train, people often call them 
\f2\i foundation models.
\f1\i0  A foundation model is a deep learning model (often an LLM, though others operate on image or audio tasks) that is sufficiently performant and sufficiently flexible to adapt to a wide range of tasks. \
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 Once we choose a foundation model upon which to base our work, the second, and often the most challenging task lies in getting our foundation model to treat our problems and data with sufficient sensitivity. For instance, GPT-4 (with over 100 trillion parameters) is very powerful. But its exposure to, say, information about presidential history, is only fleeting. To use GPT-4 to perform tasks on Miller Center data, it is likely that we would need to supplement its knowledge in efforts to focus its output on topics relevant to our audience.\
There are numerous ways to train a foundation model to work well in a specific setting. The most direct approach is called 
\f2\i model fine-tuning.
\f1\i0  This task involves deploying a local copy of the model and showing it a corpus of training data indicative of the task at hand. Researchers have shown that even a modest amount of training data (on the order of 50-100 training examples) can quickly focus a foundation model on almost any task [Liu et\'a0 al., 2022].\
\pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b\fs32 \cf0 3.5  Retrieval-Augmented Generation\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 Unfortunately even fine-tuned models make mistakes. An important point to understand about LLMs is that they contain no database of facts, no knowledge about the world aside from their understanding of language. When LLMs create text, they form statements that are statistically likely, but no additional fact checking is part of their standard operating procedure. Fortunately, an LLM\'92s notion of linguistic appropriateness is so deep that it is often enough to keep its output correct and factual. But occasionally, LLMs will 
\f2\i hallucinate
\f1\i0 , creating text that seems plausible but is factually wrong. In settings where accuracy (as opposed, say, to creativity) is crucial, this tendency requires us to add guardrails when deploying LLMs.\
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 Perhaps the most broadly implemented guardrail architecture is known as 
\f2\i retrieval-augmented generation
\f1\i0  (RAG). A RAG system consists of an LLM and a more traditional search engine. When a user submits a prompt to a RAG system, the interaction runs like this: \
\pard\tx283\pardeftab720\li600\fi-300\sb50\sa120\partightenfactor0
\cf0 1.	The prompt is presented to the LLM, which translates the user input into one or more queries for the search engine. \
2.	The search engine scours its database, retrieving documents that appear to contain an answer to the user\'92s queries. \
3.	The LLM reads and summarizes the retrieved documents, along with the user\'92s original prompt. Based on these texts, the LLM creates a summary that answers the original question. \
\pard\pardeftab720\sb60\qj\partightenfactor0
\cf0 The chief point to understand about RAG is that the LLM is only in charge of the natural language portion of the task\'97translating prompts and interpreting documents. The factual matters are handled by the search engine. So long as the search engine has indexed accurate documents, the end user should be able to interact with the system via natural language while also receiving correct information. By tying the LLM\'92s output to factual data from a document corpus, a RAG system can usually avoid the hallucination problem.\
\pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b\fs32 \cf0 3.6  Prompt Engineering\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 In the context of AI and LLMs, a 
\f2\i prompt
\f1\i0  is the information an end user gives to a model to articulate his or her information need. Research has shown that the quality of a prompt has a huge effect on the quality of a model\'92s output. In fact, improving prompt quality has been shown to be more important for output quality than model size or fine-tuning. [White et\'a0 al., 2023]. \
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 The practice of crafting a high-quality AI prompt is known as 
\f2\i prompt engineering
\f1\i0 . Prompt engineering is so fundamental that alongside its general ChatGPT documentation, OpenAI maintains documentation solely dedicated to prompt engineering. Likewise, many courses are available to help people improve their prompt engineering skills.\
\pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b\fs32 \cf0 3.7  Concluding Thoughts about Vocabulary\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 The term 
\f2\i AI
\f1\i0  today refers to deep learning models trained on huge volumes of data. In most cases, people discussing AI are interested in so-called 
\f2\i generative artificial intelligence
\f1\i0 , AI whose output is text, audio, images, or video, as opposed to older AI whose output was metadata. The arrival of generative AI is due to our reaching a historical inflection point. Computing and network hardware has grown in power in recent years, reaching a level of ability that enables cheap computation over terabytes of data. This phenomenon\'97the commodification of data and computation\'97ushered in a class of deep learning models that can, if applied thoughtfully and creatively, act as a substitute for human attention in a range of settings and tasks. Arguably 
\f2\i the
\f1\i0  cardinal challenge in deploying this new generation of AI models is finding compelling data and applications for them. These tasks\'97finding data and situating our deployments\'97will occupy the remainder of this white paper.\
\pard\pardeftab720\sb240\sa120\partightenfactor0

\f0\b\fs32 \cf0 4  Census of Miller Center Data\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 The coin of the realm in modern AI applications is machine-readable data. When considering how AI can be useful to an enterprise, the organization's data drives the discussion in at least three ways: \
\pard\tx283\pardeftab720\li600\fi-300\sb50\sa120\partightenfactor0
\cf0 1.	The topics, genres and themes expressed in the data will bear on the questions and prompts that will be posed against them. \
2.	Rights management and other questions of data accessibility and reuse will dictate how the data can be used during AI training and deployment. \
3.	The magnitude, structure and formats of the data will bear on what kinds of AI tasks the unit can complete (e.g. model training and fine-tuning). \
\pard\pardeftab720\sb60\qj\partightenfactor0
\cf0 Because data are central to the details of deploying AI, this section offers a census of the Miller Center's machine-readable data holdings. Our goal here is to describe the "crown jewels\'e2\'80  of Miller Center data, not to enumerate every byte of data we own. Collectively, these descriptions will help us structure subsequent thinking about what types of inquiry and engineering would be useful and practical for the Miller Center\
\pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b\fs32 \cf0 4.1  Presidential Recordings\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 The Miller Center is unique in its collection of original and secondary information concerning audio recordings of U.S. presidents. The Miller Center has published these recordings, as well as archival finding aids describing them, on {\field{\*\fldinst{HYPERLINK "https://millercenter.org"}}{\fldrslt 
\f3 millercenter.org}}. Additionally, scholars in the Presidential Recordings Program (PRP), continually create scholarly transcripts (in TEI XML format) of the tapes, which they publish in partnership with UVA Press. The original recordings and archival finding aids are in the public domain. Due to licensing restrictions, the PRP transcriptions of the tapes are copyright protected. \
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 Table 2 outlines the size of the presidential recording data. The table is based on the holdings in {\field{\*\fldinst{HYPERLINK "https://millercenter.org"}}{\fldrslt 
\f3 mc.org}}. This is admittedly not the full population of presidential recording data, but the number is close to the total available and gives an accurate sense of the corpus' dimensions. The \'93Total Hours\'94 column lists the total running time of all available recordings. The \'93Number of Recordings in mc.org\'94 column shows the number of discrete conversations currently housed on mc.org. \
\pard\pardeftab720\sb240\qc\partightenfactor0
\cf0  \
\pard\pardeftab720\sb120\sa120\partightenfactor0
\cf0 Table 2: Miller Center data holdings: presidential recordings.\
\

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2880
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx5760
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  President\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Total Hours\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 # in 
\f4\i mc
\f3\i0 .
\f4\i org
\f1\i0 \cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2880
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx5760
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Franklin Roosevelt\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 8\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 23\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2880
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx5760
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Harry Truman\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 10\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 20\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2880
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx5760
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Dwight Eisenhower\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 15\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 36\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2880
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx5760
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  John F. Kennedy\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 260\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 386\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2880
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx5760
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Lyndon Johnson\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 800\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 9,497\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2880
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx5760
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Richard Nixon\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 3,700\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 23,136\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2880
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx5760
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Total\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 4,793\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 33,098\cell \lastrow\row
\pard\pardeftab720\sb120\sa120\partightenfactor0
\cf0  \
\pard\pardeftab720\sb240\qj\partightenfactor0
\cf0 In addition to the public domain data described in Table 2, PRP scholars at the Miller Center have published a subset of conversations, along with carefully edited transcripts, via the UVA Press's 
\f2\i Presidential Recordings Desktop Edition
\f1\i0  (PRDE). Table 3 outlines the PRDE holdings, as of this writing. The total running time of the 4,547 recordings in PRDE is approximately 516 hours. Currently, access to the PRDE transcripts is limited to subscribers only. An important area of collaboration in the future will be discussing with UVA Press options for widening the availability of these data. In initial conversations during this paper\'92s writing, contacts at UVA Press indicated enthusiasm about collaborating with the Miller Center (especially around data sharing arrangements). A likely follow-on to this work will involve detailed discussions about this possibility. \
\pard\pardeftab720\sb240\qc\partightenfactor0
\cf0  \
\pard\pardeftab720\sb120\sa120\partightenfactor0
\cf0 Table 3: Number of recordings in PRDE.\
\

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  President\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Number of Conversations\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  John F. Kennedy\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 340\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Lyndon Johnson\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 3,972\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Richard Nixon\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 235\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Total\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 4,547\cell \lastrow\row
\pard\pardeftab720\sb120\sa120\partightenfactor0
\cf0  \
\pard\pardeftab720\sb240\qj\partightenfactor0
\cf0 In terms of data formats, the recordings are stored in mp3 at a minimum (many are stored in multiple formats). Finding aids are in modern PDF format, which means that it is easy to extract the raw text from them. The conversations listed in Table 3 have accompanying TEI XML-encoded transcripts. \
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 One closing note is in order about our PRP data. Because the transcripts of these tapes are likely to be governed by copyright, a possibly useful approach would involve obtaining transcripts of the tapes via AI. Current-generation audio-to-text AI is capable of transcribing at least the less noisy telephone conversations within the PRP corpus. The transcriptions would not be suitable for scholarly purposes. For instance, they are likely to contain some errors and they would not ascribe statements to their human speakers. However, for tasks like metadata generation (e.g. for indexing), these rough transcriptions may be useful. \
\pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b\fs32 \cf0 4.2  Presidential Oral Histories\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 As of December 2023, the Presidential Oral History Project (POHP) at the Miller Center has conducted over 700 interviews, spanning eight programs (Carter, Reagan, Bush 41, Clinton, Bush 43, Obama, Hillary Clinton, and Edward M. Kennedy). Each of these interviews generates numerous documents, including the raw audio recording of the interview, interviewee briefing books, and the final transcript. Likewise, each of these documents is a rich, long-form piece of scholarship or primary-source history. Some of these documents have been deeded and cleared for publication, while others remain confidential. \
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 The sensitive nature of undeeded interviews, and indeed the personal character of 
\f2\i all
\f1\i0  POHP data make it unique among the Miller Center's holdings. For the purposes of this data census, an exhaustive accounting of these data is unnecessary. Instead, for our purposes it is sufficient to put into the foreground the following statistics: \
\pard\tx283\pardeftab720\li600\fi-300\sb50\sa120\partightenfactor0
\cf0 \'95	Total POHP programs: 8 \
\'95	Total interviews conducted as of this writing: >700 \
\'95	Number of interviews published on millercenter.org: 504. \
\'95	Number of briefing books published on millercenter.org: 348. \
\'95	Number of PDF pages of interviews published on millercenter.org: 25,634 \
\pard\pardeftab720\sb60\qj\partightenfactor0
\cf0 We focus here on the subset of OHP data that has been published on the web because these data have been cleared and would form the basis for inclusion in any AI model. The remaining OHP interviews (i.e. those not shown in this section\'92s enumeration) may find their way into an AI system at a later time. But until they are deeded, these documents cannot be added to any proposed AI system.\
\pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b\fs32 \cf0 4.3  Miller Center Advancement and Communications Teams\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 The Miller Center \'92s Advancement team maintains several databases to manage their contacts, track giving and fundraising, and to curate our various email lists. However, these official fundraising databases are owned by University Advancement and are not directly available for use in any third-party AI applications. In this section, then, we focus on the resources that the Miller Center retains direct control over.\
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 A joint effort by Advancement and Communications stores data about every public event that the Miller Center hosts. In a variety of systems ({\field{\*\fldinst{HYPERLINK "https://millercenter.org"}}{\fldrslt 
\f3 millercenter.org}}, {\field{\*\fldinst{HYPERLINK "http://eventbrite.com"}}{\fldrslt 
\f3 EventBrite}}, and Marketing Cloud), these teams store, for each event: \
\pard\tx283\pardeftab720\li600\fi-300\sb50\sa120\partightenfactor0
\cf0 \'95	Metadata about the event (title, abstract, participants, location) \
\'95	Registrations \
\'95	Which registrants attended the event (names and demographics). \
\pard\pardeftab720\sb60\qj\partightenfactor0
\cf0 These are highly structured spreadsheet, XML and JSON data. \
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 Another crucial source of Miller Center data is our flagship website, {\field{\*\fldinst{HYPERLINK "https://millercenter.org"}}{\fldrslt 
\f3 millercenter.org}} (mc.org). Much of the PRP and POHP data listed earlier is available on mc.org. But for the sake of clarity, Table 4 gives a full accounting of the website\'92s holdings in one place. Under the rubric of mc.org, several discrete data sets are present. For instance, mc.org contains the 
\f2\i American President
\f1\i0  biographies and essays, as well as the presidential speech corpus, which we describe in the next section. Each of these sub-collections is thematically distinct. Separating them could be useful for model training purposes. But for the most part, it is easiest and most productive to consider mc.org as a single data source, since its formats and rights management details are, for the most part, singular across the site.\
\pard\pardeftab720\sb240\qc\partightenfactor0
\cf0  \
\pard\pardeftab720\sb120\sa120\partightenfactor0
\cf0 Table 4: mc.org data holdings.\
\

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Page Type\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Number of Pages in mc.org\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  American Forum\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 100\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  General Article Page\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 2,807\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Public Event\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 3,021\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Expert\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 71\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  MC Presents\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 150\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Scroller Page\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 167\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  President Bio\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 45\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  AmPres Bio\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 107\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Presidential Interview\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 536\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Presidential Recording\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 33,098\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Presidential Speech\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 1,050\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Total\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 41,152\cell \lastrow\row
\pard\pardeftab720\sb120\sa120\partightenfactor0
\cf0  \
\pard\pardeftab720\sb360\sa120\partightenfactor0

\f0\b\fs32 \cf0 4.4  Presidential Speeches\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 The Miller Center maintains a corpus of impactful presidential speeches ({\field{\*\fldinst{HYPERLINK "https://millercenter.org/the-presidency/presidential-speeches"}}{\fldrslt 
\f3 https://millercenter.org/the-presidency/presidential-speeches}}). This curated collection contains about 1,050 speeches, with entries from all 45 U. S. presidents. These speeches were enumerated as part of Table 4, but we describe them in detail in this section due to their vital importance for AI work. Each speech in the collection contains: \
\pard\tx283\pardeftab720\li600\fi-300\sb50\sa120\partightenfactor0
\cf0 \'95	The speech itself (i.e. a transcript) \
\'95	Metadata about the speech (President, date, title, location) \
\'95	An audio recording of the speech (for recent speeches) \
\'95	A video recording of the speech (for recent speeches) \
\pard\pardeftab720\sb60\qj\partightenfactor0
\cf0 Miller Center staff make the editorial decision whether to include each new speech that the president makes. And occasionally staff elect to include an especially important speech from the past. So over time this collection grows in size.\
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 While this collection is small, it punches above its weight because it is often requested by data science and political science scholars as a data set to inform their research. The presidential speech collection is available via our bulk data acquisition interface, {\field{\*\fldinst{HYPERLINK "http://data.millercenter.org"}}{\fldrslt 
\f3 data.millercenter.org}}. Our data API serves Miller Center data in machine-readable JSON format. Maintaining this service is beneficial in two ways: \
\pard\tx283\pardeftab720\li600\fi-300\sb50\sa120\partightenfactor0
\cf0 1.	It allows researchers to download large volumes of our data without increasing the load on our website servers. \
2.	It exposes our data to researchers in a file encoding that is standard in the data science world and which saves consumers the need to remove formatting and encoding information. \
\pard\pardeftab720\sb60\qj\partightenfactor0
\cf0 We unveiled {\field{\*\fldinst{HYPERLINK "http://data.millercenter.org"}}{\fldrslt 
\f3 data.millercenter.org}} in 2022 and since then it has become quite popular, with, on average, over 50 downloads per day of the speech collection.\
\pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b\fs32 \cf0 4.5  Miller Center Data in Amazon Web Services\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 Miller Center IT staff stores the lion's share of our data (by byte volume) in Amazon Web Services (AWS). This catch-all descriptor actually contains three sub-collections of data. First, AWS contains the multimedia content that backs {\field{\*\fldinst{HYPERLINK "https://millercenter.org"}}{\fldrslt 
\f3 millercenter.org}}\'e2\'80\'94items like POHP transcript and briefing book PDFs and PRP audio recordings. Secondly, we use AWS to house backups of our raw video footage and assets (metadata, images, etc.) related to editing together the final versions of our public event videos. Lastly, because we use AWS as a backbone of millercenter.org, there is a large body of transaction log data in AWS. These logs capture how end users use our materials on millercenter.org. For example, the logs can tell us which presidential speeches, PRP recordings, and POHP interviews are requested most often.\
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 Table 5 lists the main holdings in AWS. \
\pard\pardeftab720\sb240\qc\partightenfactor0
\cf0  \
\pard\pardeftab720\sb120\sa120\partightenfactor0
\cf0 Table 5: Miller Center Data Holdings: Amazon Web Services (AWS).\
\

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2880
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx5760
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Bucket\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Items\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 # Size\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clmgf \clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2880
\clmrg \clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx5760
\clmrg \clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\qc\partightenfactor0
\cf0  Public\cell 
\pard\intbl\itap1\cell 
\pard\intbl\itap1\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2880
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx5760
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  POHP Briefing Books\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 303\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 0.88 GB\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2880
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx5760
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  POHP Transcripts\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 2,073\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 2.3 GB\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2880
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx5760
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Presidential Speeches\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 9,439\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 280.5 GB\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2880
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx5760
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  PRP Recordings\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 97,124\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 2,300 GB\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2880
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx5760
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  FirstYear\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 1,091\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 0.2 GB\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2880
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx5760
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Total\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 121,229\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 3,983.82 GB\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clmgf \clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2880
\clmrg \clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx5760
\clmrg \clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\qc\partightenfactor0
\cf0  Backup/Private Data\cell 
\pard\intbl\itap1\cell 
\pard\intbl\itap1\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2880
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx5760
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Misc\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 11,199\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 1,400 GB\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2880
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx5760
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Transaction Logs\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 1.81M\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 4.3 GB\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2880
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx5760
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Video Backups\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 448,832\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 620,000 GB\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2880
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx5760
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Total\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 2.26M\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 62004.34 GB\cell \lastrow\row
\pard\pardeftab720\sb120\sa120\partightenfactor0
\cf0  \
\pard\pardeftab720\sb360\sa120\partightenfactor0

\f0\b\fs32 \cf0 4.6  Video Housed in YouTube\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 The Miller Center has a large collection of digital video, containing recordings of our public events. An accounting of these assets is available by surveying our holdings in {\field{\*\fldinst{HYPERLINK "https://www.youtube.com/@millercenter32"}}{\fldrslt 
\f3 YouTube}}. We use YouTube to host public copies of our final, edited event programs. Table 6 describes our YouTube data. \
\pard\pardeftab720\sb240\qc\partightenfactor0
\cf0  \
\pard\pardeftab720\sb120\sa120\partightenfactor0
\cf0 Table 6: YouTube video and transcript holdings.\
\

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx1440
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2880
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx5760
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx7200
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Source\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Num. Videos\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Num. Transcripts\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Avg. Video Length\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Avg. Transcript Size\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Total Size of Transcripts\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx1440
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2880
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx5760
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx7200
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Main Channel\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 651\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 627\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 1 hr\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 168k\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 52 MB\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx1440
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2880
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx5760
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx7200
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Am. Forum\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 820\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 776\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 1 hr\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 18k\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 6.5 MB\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx1440
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx2880
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx5760
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx7200
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Total\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 1,471\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 1,403\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 \cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 \cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 58.5 MB\cell \lastrow\row
\pard\pardeftab720\sb120\sa120\partightenfactor0
\cf0  \
\pard\pardeftab720\sb360\sa120\partightenfactor0

\f0\b \cf0 4.6.1  Data Cleaning and Pre-Processing\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0 \cf0 For the most part, the Miller Center\'92s data is \'93clean,\'94 at least by internet standards. Using these data as input for models would not require us to spend inordinate time on pre-processing. As a point of comparison, data obtained from the open internet is often weighed down by formatting metadata, odd data encodings, and other publishing artifacts that must be removed prior to use in a model. Since we can obtain all of the data described in this section without downloading it from the internet, we can avoid the heaviest pre-processing. However, even our relatively clean data will demand some amount of pre-processing before we use it for AI tasks.\
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 For example, if we pursue a data sharing arrangement with UVA Press, an important question will be how to handle the XML markup. The naive approach to this data cleaning task would involve simply removing the XML tags from the transcripts (AI models cannot understand XML). However, this would cause us to lose all of the semantic information that has been added to those documents via editorial markup. Thus it may be the case, in this example, that we follow a smarter data cleaning regime. Perhaps, for instance, we should translate some of the XML tags to text that we add as editorial description to each transcript. \
The transcripts obtained from our YouTube videos gives another perspective on this issue. These data are time-coded. That is, the transcript for a given event is not simply a text file. Instead, it is a structured document consisting of a listing of entries. Each entry contains a time code (the offset in the video where the transcript starts and stops) and the spoken text for that block of time. To prepare these coded entries for use in a model, at a minimum we would need to concatenate the text into a long, single text file. Alternatively, we might translate each start and stop time into English text so that a model could understand that a certain block of text relates to a certain span of time.\
The point of these examples is that, for each data source that we bring into our modeling, we will need to consider carefully how best to prepare the data. Once we decide on a strategy to apply to each data source, the cleaning can be automated. But taking adequate time for strategizing, and implementing the automation is a worthwhile investment. A truism of AI research is that data preparation is the most crucial step in modeling. Given the provenance of our data, our data cleaning will be easier than it would be if we were obtaining our text from \'93the wild." But even with a clean starting point, we must remain mindful of how best to present our text to the algorithms that will support our downstream AI applications.\
\pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b\fs32 \cf0 4.7  Closing Thoughts on Miller Center Data\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 Figure 2 schematizes the various data sources that would be available if the Miller Center undertook a language modeling effort of its own. The left portion of the figure shows six corpora that we described in this section. The overlaps between the portions show real-world intersections. For instance, the PRP transcripts are included in the contents of mc.org. Likewise with the Oral History transcripts: oral history transcript text appears as content on mc.org. On the other hand, the OHP briefing books separate from the website.\
\pard\pardeftab720\fi360\sb240\qc\partightenfactor0
\cf0  \
\pard\pardeftab720\sb120\sa120\qc\partightenfactor0
\cf0  \
\pard\pardeftab720\sb120\sa120\partightenfactor0
\cf0 Figure 2: Available text data sources for training Miller Center language models. N.B. Items are not drawn to scale.\
\pard\pardeftab720\fi360\sb240\qj\partightenfactor0
\cf0 Figure 2 shows that we have approximately 43,000 \'93pages" of Miller Center-specific text. This is a sufficient amount of text for tasks like model fine-tuning and evaluation. It would also make an excellent RAG search index. But for more ambitious modeling tasks we may need to flesh out our local holdings with additional data sources, since deep learning models require such vast training corpora. Luckily, the research community has made several large English language data sets available. Three of these are shown in the right half of Figure 2. The topmost block in that figure refers to the familiar English language {\field{\*\fldinst{HYPERLINK "http://en.wikipedia.org"}}{\fldrslt 
\f3 wikipedia}} database. \'93The Pile" refers to an 800-GB corpus that was used to train several LLMs such as LLama (Facebook) and Palm (Google) [Gao et\'a0 al., 2020]. The C4 entry refers to the \'93Colossal Clean Crawled Corpus" [Dodge et\'a0 al., 2021], another open dataset intended for LLM training. These resources have all been created, at least in part, in efforts to allow organizations like the Miller Center to supplement their local data holdings to build LLMs. \
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 Figure 2 only includes textual data, not binary data, such as images, video and audio. For purposes of LLM training, only text is relevant. However, the Miller Center contains ample binary data such as the PRP recordings, OHP interview tapes, and video assets from public events. We include consideration of audio content in Section 6.3.2, in the context of helping PRP scholars with audio transcription. But for the most part, we recommend saving binary data for a second round of AI work because multimedia content is more difficult than text to use in AI applications. We discuss this decision again in our concluding remarks in Section 7.\
When we discuss data requirements in the following sections, we will refer often to Figure 2 as we imagine different model training and evaluation regimes.\
\pard\pardeftab720\sb240\sa120\partightenfactor0

\f0\b\fs32 \cf0 5  AI Initiatives Elsewhere on Grounds\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 Because AI work tends to be resource-intensive, finding productive points of collaboration and cross-pollination is an important step as we endeavor to formulate our plans and ambitions in this space. Not surprisingly, UVA has numerous AI initiatives in the works and recently concluded. This section outlines the most relevant of these initiatives, with the goal of identifying possible avenues for future collaboration and increasing our knowledge of expertise available on Grounds.\
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 Many units across Grounds have begun AI initiatives. For our purposes, four of these are the most relevant, due to their high impact and their proximity to the Miller Center, institutionally speaking: \
\pard\tx283\pardeftab720\li600\fi-300\sb50\sa120\partightenfactor0
\cf0 1.	The UVA Futures Initiative: a year-long project that will result in a strategic recommendation to Jim Ryan about AI and the future of universities. \
2.	The Provost\'92s Generative AI in Teaching and Learning Task Force [now complete]: an in-depth study of how UVA should integrate AI into teaching. \
3.	The Vice-Provost for Research\'92s Task Force on AI in Research: a forthcoming survey of how AI is being used in research across Grounds. \
4.	Darden\'92s Artificial Intelligence Initiative (DAII): a website and a roster of public events that crystalize how AI is impacting the business world and the research areas of Darden faculty. \
\pard\pardeftab720\sb180\sa120\partightenfactor0

\f0\b\fs32 \cf0 5.1  The University Futures Initiative\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 Currently, the most ambitious entity in the AI space at UVA is {\field{\*\fldinst{HYPERLINK "https://as.virginia.edu/uva-launches-futures-initiative-chart-next-decade-higher-ed"}}{\fldrslt 
\f3 the Futures Initiative}}. The chief aim of the Futures Initiative is to develop a proposal for university leadership that will help UVA work proactively towards a future ushered in by disruptive technologies such as AI and large language models. A core part of the Futures Initiative is the Futures Initiative Group, a body of internal and external UVA thought leaders that is tasked with strategic thinking about how the work of universities is likely to change in the near future. \
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 During spring 2024 the aim of the Futures Initiative Group is to form a Future Initiatives Working Group (FIWG), consisting of thought leaders from across Grounds. The membership of this group will be seeded by recommendations from deans and center directors, and the goal of the group is to pursue focused questions at a subcommittee level. The formation of the FIWG is an opportunity for the Miller Center to join the larger discussion about AI by nominating personnel for a subcommittee. This would have the twin benefits of positioning us at an important table and giving us a way to seek points of cross-Grounds collaboration in our AI work.\
A particularly exciting aspect of the Futures Initiative is its inherent interdisciplinarity and its intentional inclusion of partners from the liberal arts. During an announcement about the Futures Initiative, Dean of the University's College and Graduate School of Arts and Sciences, Christa Acampora said, "To understand, adapt, and solve these urgent problems, UVA will need to realize even greater interdisciplinarity across academic fields.  The liberal arts and sciences are crucial for this project because \'93now more than ever\'94 we need a more capacious understanding of what is human, more than human, and humane.\'e2\'80  Though AI is first and foremost a technical field, the generous funding of the Futures Initiative ($1.5M from the Strategic Investment Fund, for the period 2024-2028) shows that at UVA there will be ample room for humanistic players such as the Miller Center to contribute to the discussion of how best to respond to the challenges posed by novel AI technologies.\
\pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b\fs32 \cf0 5.2  Provost Task Forces on Artificial Intelligence\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 Some of the keenest questions about AI's role at the university center on teaching and learning\'e2\'80\'94how will AI change the experience of students and instructors? In spring of 2023 the UVA provost's office convened a {\field{\*\fldinst{HYPERLINK "https://provost.virginia.edu/subsite/genai"}}{\fldrslt 
\f3 Generative AI in Teaching and Learning Task Force}}. The final report of this committee examines how generative AI will affect teaching and learning in three main ways: \
\pard\tx283\pardeftab720\li600\fi-300\sb50\sa120\partightenfactor0
\cf0 1.	What students learn, \
2.	How students learn, and \
3.	How learning is assessed. \
\pard\pardeftab720\sb60\qj\partightenfactor0
\cf0 The outcome of the Generative AI in Teaching and Learning Task Force is twofold. First, the task force created a {\field{\*\fldinst{HYPERLINK "https://provost.virginia.edu/subsite/genai/faqs"}}{\fldrslt 
\f3 web-based tool}} intended to help instructors and students answer practical questions about appropriate uses of AI in UVA classroom settings. Second, the task force released a {\field{\*\fldinst{HYPERLINK "https://provost.virginia.edu/subsite/genai/task-force-report"}}{\fldrslt 
\f3 final report}}, outlining its processes and findings. Characterizing fall 2023 as an inflection point, the task force encourages UVA not to "waste a good crisis,\'94  urging faculty to engage in structured thinking about their own plans and university leadership to supply "significant administrative suppor   for the UVA community's efforts to integrate AI into teaching and learning.\
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 With the teaching and learning task force completed, the Vice Provost for Research recently convened a new task force to examine how AI is entering research efforts across Grounds. This initiative is in its early stages. But a major item on the task force\'92s agenda is completing a survey of AI-enabled research projects at UVA. Recently, Raf Alvarado\'97a member of the AI Research Task Force\'97interviewed Marc Selverstone and Miles Efron as part of this survey. He was enthusiastic about the projects we described, and he plans to feature the Miller Center\'92s work in the final report of the task force. Alvarado also described several funding opportunities, which we return to in Section 5.5\
\pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b\fs32 \cf0 5.3  The Darden Artificial Intelligence Initiative\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 Darden and the Batten Institute have joined forces to form {\field{\*\fldinst{HYPERLINK "https://www.darden.virginia.edu/intelligence"}}{\fldrslt 
\f3 UVA Darden's Artificial Intelligence Initiative}} (DAII). Whereas the Futures Initiative Group and the provost\'92s task forces are intentionally high-level, the DAII is more narrowly scoped, focusing on three main topics: \
\pard\tx283\pardeftab720\li600\fi-300\sb50\sa120\partightenfactor0
\cf0 \'95	AI and Marketing \
\'95	AI and the Future of Work \
\'95	AI and Economic Progress. \
\pard\pardeftab720\sb60\qj\partightenfactor0
\cf0 To foster critical thinking about these issues, the DAII aims to "[bring] together a diverse, multidisciplinary group of leading scholars to shape the discussion [on Grounds] about artificial intelligence and its related technologies, embracing a holistic perspective.\'e2\'80  Darden's AI initiative maintains a program of public events related to these three topics, which will be important to stay abreast of for the Miller Center's own strategic thinking.\
\pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b\fs32 \cf0 5.4  Closing Remarks on Cross-Grounds AI Initiatives\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 Together, these four initiatives (the Futures Initiative, the two provost-initiated programs, and the Darden AI Initiative) show three important facts about the state of play with respect to AI on Grounds in early 2024: \
\pard\tx283\pardeftab720\li600\fi-300\sb50\sa120\partightenfactor0
\cf0 1.	University leadership sees AI and data-centered computing as a strategic opening that merits investment in terms of infrastructure, teaching, and research. \
2.	Vital work in this space is being conducted both in centralized and de-centralized initiatives across Grounds. The Miller Center may want to target specific initiatives as places to focus messaging about our AI work. The Futures Initiative is, to the best of our understanding, currently choosing working group members. \
3.	The emphatic inclusion of liberal arts stakeholders in the university's AI planning presents an opening for the Miller Center to claim a seat at the table, as a uniquely positioned unit, at the nexus of humanistic inquiry and cutting-edge technical work. \
\pard\pardeftab720\sb180\sa120\partightenfactor0

\f0\b\fs32 \cf0 5.5  Resource Availability and the Funding Landscape for AI Work, On- and Off-Grounds\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 During our interview with Raf Alvarado for the VPR\'92s AI Research Task Force, we learned that at this time, funding for AI research on Grounds in fairly unstructured but nevertheless available. The main source of support available for research into AI applications is {\field{\*\fldinst{HYPERLINK "https://www.rc.virginia.edu"}}{\fldrslt 
\f3 UVA Research Computing}} (URC). URC offers compute, data storage, and training resources to the UVA community, including special support for AI in the form of GPU access (i.e. the hardware used for AI model training), parallel implementations of the major AI software libraries (e.g. Keras/TensorFlow/PyTorch), and tera-scale data storage. These resources are available on a pay-as-you-go model. Raf Alvarado suggested that in the future, UVA will likely offer financial support to help units pay for these services, but at the time, no formal AI support source is broadly available.\
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 As its name implies, the URC computing infrastructure is available only for research purposes. For any production systems, the Miller Center would need to find other platforms to build on. In Section 6 we propose several AI projects that would have a research component to them. As we weigh our options in terms of project deployments, one consideration might be whether undertaking projects with a research component might align the Miller Center with support opportunities available at UVA.\
Regardless of whether we obtain our computing resources from URC or elsewhere, there is no shortage of platforms available for the Miller Center\'92s work. AI computing resources are increasingly easy to marshal. The Miller Center has already moved almost all of its IT portfolio to the AWS cloud, and Amazon provides ready access to all of the storage and compute resources that we would need for any AI project. For specialized services, the major AI platforms are all available via public APIs, which would allow the Miller Center to call, say, GPT-4 models, or the OpenAI embeddings interface from our own code. Architecting our AI software systems will be a crucial task as we roll out intelligent systems. But given the increasing industry homogeneity in terms of API exposure, access to models and software is unlikely to pose a significant problem. The more immediate stricture will be the cost of these platforms.\
To fund our use of these infrastructural elements, a number of new funding opportunities may be of interest. \
The National Science Foundation is currently starting {\field{\*\fldinst{HYPERLINK "https://nairrpilot.org"}}{\fldrslt 
\f3 the National AI Research Resource Pilot}} (NAIRR), a project aimed at supporting AI research by providing industry-scale computing infrastructure. NAIRR\'92s first round of funding\'97an open call for requests for GPU access\'97is currently open, with a request deadline of March 1, 2024. If this date is too early for the Miller Center to submit a request, NSF has indicated that future, possibly more broadly scoped rounds will come online in the future. In addition to grants for GPU access, NAIRR offers {\field{\*\fldinst{HYPERLINK "https://nairrpilot.org/pilot-resources"}}{\fldrslt 
\f3 a web-based repository of AI resources}} like pre-trained models, corpora, and software. \
A second possible source of support is {\field{\*\fldinst{HYPERLINK "https://www.neh.gov/AI"}}{\fldrslt 
\f3 the National Endowment for the Humanities\'92 Perspectives on AI}}, a research initiative that NEH launched in 2023. The Humanities\'92 Perspectives on AI Initiative currently has five lines of funding, each with its own focus and target audience. \
The infrastructure and support options available for any Miller Center AI initiatives is certainly broader than what we can outline in this white paper. However, as this brief section shows, at both local and national levels, there is increasing interest in funding humanistic applications of AI. Between the Miller Center\'92s current base of support, funding and technology programs on Grounds, and commercial and government resources, the resources available to the Miller Center are deep.\
\pard\pardeftab720\sb240\sa120\partightenfactor0

\f0\b\fs32 \cf0 6  Possible Applications of AI Technology to Advance the Miller Center\'92s Mission\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 This section outlines several projects that the Miller Center could undertake to increase its impact and pursue its mission by applying AI technologies. \
\pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b\fs32 \cf0 6.1  A Note on the Cost of AI Projects\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 The projects we outline in this section would incur several types of cost. Some of the computation would take place on servers in the Miller Center\'92s private AWS cloud (about $10/month per server). However, the bulk of the proposed work would take the form of calls to public APIs (e.g. from OpenAI, AWS, Google). API costs come in two varieties: \
\pard\tx283\pardeftab720\li600\fi-300\sb50\sa120\partightenfactor0
\cf0 1.	One-time upfront costs for model training \
2.	Ongoing costs for workload requests. \
\pard\pardeftab720\sb60\qj\partightenfactor0
\cf0 At this time, AI companies charge for API usage on a per-token basis. That is, the more words (or audio content) we ask the model to read or create, the higher our cost. These costs vary from service to service. \
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 As a point of reference, we offer two cost scenarios, both imagined as a system hosted on OpenAI\'92s cloud.\
If we ran an LLM-based service using GPT-3.5 (no fine tuning) that was only for in-house use by scholars, the cost would be fairly low. If each session involved 100,000 tokens inbound (say, asking the system to read an OHP interview plus instructions) and 2,000 tokens outbound, and scholars initiated 10 sessions per day, the cost would be about $24 per month, as shown in Table 7. The cost of this system would be significantly higher if we needed to rely on a fine-tuned model, as we can see in Table 8.\
\pard\pardeftab720\sb240\qc\partightenfactor0
\cf0  \
\pard\pardeftab720\sb120\sa120\partightenfactor0
\cf0 Table 7: Costs for a GPT-3.5 system for in-house use only.\
\

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Item\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Cost\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Input\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 100,000 tokens \'d7 $0.0005 per 1k tokens = $0.05\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Output\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 2,000 tokens \'d7 $0.0015 per 1k tokens = $0.003\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Num. Sessions\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 10\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Total\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 ($0.05 + $0.003) \'d710= $0.53 / day = $15.9/month\cell \lastrow\row
\pard\pardeftab720\sb120\sa120\partightenfactor0
\cf0  \
\pard\pardeftab720\sb480\qc\partightenfactor0
\cf0  \
\pard\pardeftab720\sb120\sa120\partightenfactor0
\cf0 Table 8: Costs for a fine-tuned GPT-3.5 system for in-house use only.\
\

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Item\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Cost\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Input\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 100,000 tokens \'d7 $0.003 per 1k tokens = $0.3\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Output\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 2,000 tokens \'d7 $0.012 per 1k tokens = $0.024\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Num. Sessions\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 10\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0  Total\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 ($0.3 + $0.024) \'d710= $3.24 / day = $97.2/month\cell \lastrow\row
\pard\pardeftab720\sb120\sa120\partightenfactor0
\cf0  \
\pard\pardeftab720\sb240\qj\partightenfactor0
\cf0 By comparing Tables 7 and 8, it is clear that fine tuning raises costs substantially. The other principal cost driver is traffic volume. In general, costs scale linearly with the amount of traffic sent to the model. \
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 If we determine that we would like to host a public-facing AI system on mc.org, the costs for using hosted models would become prohibitive. In such a case, self-hosting our model instead of calling a public API might become an attractive option. As a point of comparison, hosting a \'93small" LLM such as Facebook\'92s Llama-2 7B on AWS would cost approximately $1,000 per month. In contrast, using the numbers from Table 7, if we used OpenAI\'92s model to field 1,000 calls per month (a very low number, given mc.org\'92s traffic), our costs would be almost $1,600 per month. Finding the threshold where a local model becomes cost effective is difficult in general, but a common industry rule of thumb is that if our traffic generates more than about 1,000 model invocations per day, hosting our model becomes cost effective [Vivek, 2023, Javaness, 2023]. With traffic below about 1,000 calls per day, relying on public APIs is usually cheaper. \
One near certainty is that over time the costs associated with AI will drop. AI hardware is always declining in cost, and the AI services market is profoundly competitive. Both of these factors will put downward pressure on AI costs in the coming years. In the meantime, a common strategy for AI deployment is to start with a system that is highly performant but deployed to a limited audience. \
\pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b\fs32 \cf0 6.2  Low-Hanging Fruit: Simple Options with High Impact\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 Before we introduce more ambitious ideas in Section 6.3, we offer several AI applications the Miller Center could undertake that would have high impact but little risk exposure and modest work requirements. \
\pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b \cf0 6.2.1  Informally Integrating AI Tools into Miller Center Work\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0 \cf0 A key aspect of modern AI tools is their broad application. Knowing when and how to use AI, and being able to wield AI tools creatively are key skills for modern office work. To help the Miller Center (ideally scholars and staff) capitalize on the current state of the art, a few simple actions could go a long way.\
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 First, it could be advantageous to schedule a periodic brown bag or informal tutorial on creative applications of AI. We could draw on local talent, and optionally invite external guests to participate in such a forum. One approach might be for a designated staff member (e.g. Miles Efron) to handle the first installments of such a brown bag series, with the goal of providing instruction in using these tools for the kinds of tasks that come up often at the Miller Center. Initial topics could include prompt engineering best practices, using ChatGPT to analyze spreadsheet data, and a comparison of AI tools such as ChatGPT, Bard and Anthropic\'92s Claude. After time, once it has momentum, the series could be opened to guest speakers who could present on their own experiences using AI in their work.\
Alongside a live instructional series, we could make a living document about AI technologies available to Miller Center staff. The document could contain, among other things: \
\pard\tx283\pardeftab720\li600\fi-300\sb50\sa120\partightenfactor0
\cf0 \'95	Reviews of online courses on AI. \
\'95	Reports on successful use of AI in the workplace. \
\'95	A listing of tools available to Miller Center staff and descriptions of their applications to our work. \
\'95	Guidelines for effective prompt engineering. \
\pard\pardeftab720\sb60\qj\partightenfactor0
\cf0 The goal of this document would be to help Miller Center staff integrate AI into their daily workflow by highlighting tasks and settings where AI can offer real benefits for completing daily tasks.\
\pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b \cf0 6.2.2  Expanding our Data Portal, data.millercenter.org\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0 \cf0 Miller Center staff rolled out a data portal, {\field{\*\fldinst{HYPERLINK "https://data.millercenter.org"}}{\fldrslt 
\f3 data.millercenter.org}}, and its API backend {\field{\*\fldinst{HYPERLINK "https://api.millercenter.org"}}{\fldrslt 
\f3 api.millercenter.org}}, in 2022. The goal of these services is to allow researchers to download Miller Center content in research-friendly formats without overloading our production web servers. Since unveiling these services, we have seen consistent interest in them, with about 50 data downloads per day. Currently, the data portal only serves the text and metadata associated with the 1,050 speeches in the millercenter.org presidential speech collection. A logical and easy improvement we could make would be to flesh out our data offerings, increasing the types of data we serve and the functionality of our data API. These changes would help increase the Miller Center\'92s profile in the data and natural language processing (NLP) communities.\
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 To increase the value of our data API, there are two ways we might expand our data offerings. \
First, we can add additional types of data to our API. In addition to the presidential speeches, it would be a simple matter to make available the POHP transcripts that we already host on {\field{\*\fldinst{HYPERLINK "https://millercenter.org"}}{\fldrslt 
\f3 millercenter.org}}, assuming copyright issues would permit it. Likewise, for each of the "scrollers\'e2\'80  that we host on the Listening to the Presidency website section, we could add the associated transcript to the data portal. Again, copyright issues would dictate the ultimate decision to include or exclude transcripts. \
Second, we could add richer metadata and functionality to the data portal's underlying REST API. For example, an important step in most AI work with natural language text is deriving so-called "text embeddings.\'e2\'80  Text embeddings are themselves an AI product. They represent natural language text in numerical form, such that the text's underlying semantics become computationally tractable. The first step of almost all modern AI work involves transforming input text into embeddings. We could increase the utility of {\field{\*\fldinst{HYPERLINK "https://datamillercenter.org"}}{\fldrslt 
\f3 data.millercenter.org}} by pre-computing text embeddings for all exposed text and then making those embeddings available to clients. This would greatly enhance the value of our service to researchers. \
The aim of improving our data service would be, in part, to strengthen public perceptions of the Miller Center as a force in the NLP and data community. As part of this effort, we might announce API improvements on standard NLP and AI lists. For researchers and students (our data is often used for AI course projects) {\field{\*\fldinst{HYPERLINK "https://data.millercenter.org"}}{\fldrslt 
\f3 data.millercenter.org}} is a useful tool. Investing in increasing its functionality, offerings, and visibility could be a boon to the Miller Center\'92s reputation in the data and AI communities.\
\pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b \cf0 6.2.3  Improving the {\field{\*\fldinst{HYPERLINK "https://millercenter.org"}}{\fldrslt 
\f5 mc.org}} Site Search Engine\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0 \cf0 In 2023 the Miller Center Web team overhauled the search engine that supports our flagship website, {\field{\*\fldinst{HYPERLINK "https://millercenter.org"}}{\fldrslt 
\f3 mc.org}}. Search plays an invaluable part of users\'92 experience with our website\'97visitors used our search engine almost 200,000 times in 2023, and since unveiling our search improvements, search volume has doubled. Given the core role our search engine plays in users\'92 interaction with mc.org, it would be advantageous to use AI to improve our search engine.\
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 Due to technical limitations, there are currently two major gaps in our site search engine\'92s index: \
\pard\tx283\pardeftab720\li600\fi-300\sb50\sa120\partightenfactor0
\cf0 1.	Presidential recordings. People can search our corpus of recordings by metadata (title, speaker name, date), but not the content of each recording. \
2.	Public events. As with the recordings, people can find information about events based on metadata, but not based on the spoken contents of each public event. \
\pard\pardeftab720\sb60\qj\partightenfactor0
\cf0 AI presents a clear path to filling these gaps. To improve our site search engine, we could add invisible text fields to our web content. The new content would be obtained via AI. It would never be displayed to humans. But we could use it to index the pages, allowing users to search the recordings and events by content.\
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 In terms of the presidential recordings, current-generation audio-to-text models are sufficiently accurate to transcribe the recordings 
\f2\i for search purposes
\f1\i0 . That is, we would only use these transcriptions to support search, not as a visible field when displaying content on mc.org. It may be the case that the noisiest of the recordings would remain un-transcribable by AI. However, measuring the \'93noisiness" of these recordings is a task that we could automate. Based on experimentation, we could easily derive a threshold of clarity, only using AI to transcribe those recordings whose audio quality exceeds a certain value.\
For the public events, no additional processing is needed. Since we host videos of our events on YouTube, Google creates transcripts of our events automatically. To add these transcriptions to our search engine, all we need to do is to download them and attach each transcript to its corresponding event on the site. \
The main work of this modest project would be 
\f2\i A
\f1\i0 ) assessing how to handle the problem of noisy recordings and then 
\f2\i B
\f1\i0 ) making the needed changes to the website. The work of attaching the transcripts to their pages on mc.org would be a fairly simple programming task. Finally, we would need to build some user interface changes into the site search engine to allow users to include or exclude the AI-generated full-text search. However, none of these tasks is difficult.\
In terms of cost, the main cost would come from obtaining the AI-generated recording transcripts. However, even this is a modest outlay. If we transcribed every minute of audio shown in Table 2 using OpenAI\'92s {\field{\*\fldinst{HYPERLINK "https://openai.com/research/whisper"}}{\fldrslt 
\f3 Whisper}} audio-to-text AI, the cost would be about $1,725. If we limited transcription to relatively \'93clean" recordings, this cost would go down.\
\pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b\fs32 \cf0 6.3  Ambitious, Moonshot-Type Applications\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 While our previous section offered simple, practical ways to leverage AI technologies at the Miller Center, in this section, we offer more ambitious recommendations. How could the Miller Center marshal AI's boldest promises to revolutionize its work and qualitatively increase its impact? This section recommends three approaches.\
\pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b \cf0 6.3.1  A Miller Center Language Model\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0 \cf0 During discussions about future AI initiatives at the Miller Center, several scholars have imagined the value of a native Miller Center large language model. The aim of a Miller Center LLM would be to support wide-ranging, interactive queries into presidential history and politics, drawing on the Miller Center\'92s unique data to formulate answers.\
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 At least three concrete use cases for a Miller Center LLM arose during preparation of this white paper: \
\pard\tx283\pardeftab720\li600\fi-300\sb50\sa120\partightenfactor0
\cf0 \'95	Miller Center CEO Bill Antholis imagined a system where users could interact with all conversations where presidents discuss U.S.-China relations. \
\'95	Miller Center scholar Guian McKee discussed the research value of a system that could identify all moments in PRP recordings where presidents or their staff spoke in ways that violate the public trust. \
\'95	Miller Center scholar Barbara Perry suggested that an AI-based system could help researchers conduct a follow-up to the {\field{\*\fldinst{HYPERLINK "http://firstyear2017.org"}}{\fldrslt 
\f3 FirstYear project}}, focusing on presidential second terms. \
\pard\pardeftab720\sb60\qj\partightenfactor0
\cf0 Each of these cases speaks to the same underlying challenge: for researchers and other Miller Center audiences, there is a tremendous opportunity in finding a way to bring novel context to the entirety of the Miller Center\'92s data universe. Building a system that would allow its users to interact with Miller Center data semantically\'97seeking themes and trends, not simply keywords and tags\'97is arguably 
\f2\i the
\f1\i0  breakthrough that AI affords us.\
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 To an end user, such a system might look like a ChatGPT-style conversational agent. The goal would be to allow the user to enter an initial query and then re-query the model based on the first results. Through an iterative process, users should be able to retrieve data, request summaries of the retrieved data, and add follow-on queries based on these summaries. Each of the use-cases listed above is similar insofar as the questions seek a retrieved data set that is in some sense finite, but whose edges are not clear cut (not all discussions of U.S.-China relations, breeched public trust, or presidential second terms are clearly labeled as such). This semantic similarity and the underlying interest in iterative, incremental querying that would distinguish a Miller Center LLM from a more familiar search application.\
There are numerous architectures developers could plausibly use to build this \'93Miller Center LLM." A full reckoning of this decision is outside our current scope. But for the remainder of this section, we offer initial thoughts into this project\'92s design decisions. Our goal here is not to finalize the system, but to help readers understand what decisions would need to be made, and what resources secured, to bring this to completion.\
In light of our discussion of the Miller Center\'92s data holdings in Section 4, there are three main architectures a system like this could rely on.\
A first approach would be to build, from scratch, a true Miller Center LLM. Doing this would necessitate using all of the data sources (internal and external) shown in Figure 2. In order to give our model enough training data, we would need to supplement our data crown jewels with external sources such as Wikipedia, the \'93Pile" and the C4 corpus. This would be a hefty engineering task. It would require us to find adequate storage and GPU/compute resources. However, this is a plausible path forward.\
A more modest approach would be to use our internal data sources (i.e. the left half of Figure 2) to fine-tune an existing foundation LLM. This approach would have several advantages over a from-scratch LLM. For instance, it would require much lighter resource allocation, both in storage and compute. Secondly, it would free development from the emphatically non-trivial data cleaning and data selection work that training a full LLM would necessarily require. However, fine tuning is most successful when we want the resulting model to perform well on single, well-defined type of task. In this case, initial discussions sound like retaining flexibility in our final model is important, a consideration that may argue against the fine tuning approach.\
Perhaps the clearest path to developing a system like this is not to train a new LLM at all, but rather to create a retrieval-augmented generation (RAG) system. As we discussed in Section 3.5, RAG systems combine a search engine and an LLM to create a conversational system that \'93knows" information stored in text documents. The advantage of RAG for a problem like this one is that it will allow us to capitalize most directly on our data. With a purely LLM-driven system, the knowledge in our data would only be retrievable indirectly, insofar as it ends up encoded in the model\'92s parameters. In a RAG system, however, the model would essentially act as a broker, finding passages from our documents that using a general-purpose LLM to contextualize what the passages say.\
\pard\pardeftab720\fi360\sb240\qc\partightenfactor0
\cf0  \
\pard\pardeftab720\sb120\sa120\qc\partightenfactor0
\cf0  \
\pard\pardeftab720\sb120\sa120\partightenfactor0
\cf0 Figure 3: Architecture of a Miller Center LLM/RAG question answering system.\
\pard\pardeftab720\fi360\sb240\qj\partightenfactor0
\cf0 Figure 3 sketches a likely architecture for a Miller Center LLM/RAG system. Information would enter the system via this pipeline: \
\pard\tx283\pardeftab720\li600\fi-300\sb50\sa120\partightenfactor0
\cf0 1.	Our documents\'97recordings, interviews, public event transcripts, and mc.org content\'97would be translated in \'93text embeddings" by a service such as OpenAI\'92s. These text embeddings translate each document (or sub-document chunk) into a representation amenable for use by LLMs. \
2.	A vector database stores the embeddings. This database is essentially the index of our RAG system. Pinecone is a cloud-based vector database provider that would be a likely candidate for this task. \
3.	Miller Center staff would develop software using the OpenAI ChatGPT and LangChain API\'92s. This software handles incoming user queries, searches over the vector database, and finally, translates retrieved documents into conversational English. \
\pard\pardeftab720\sb60\qj\partightenfactor0
\cf0 Users could interact with the system via a new portal on mc.org, or on a newly created website; the point is that a familiar web interface would host the service. Incoming queries would interact with the OpenAI/LangChain code (hosted in AWS, probably), and the final results and interaction would be handled by the web interface.\
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 This sketch is a fully plausible way to build a system that could support broad queries against Miller Center information. Given the novelty and ambitiousness of this task, however, it would be important to consider in-depth planning and research before settling on a final system architecture. \
An important design question related to a Miller Center \'93LLM" is who the supported audience will be. If the tool will be limited to use by Miller Center scholars, we could deploy it with fairly modest costs. The services shown in Figure 3 all charge based on usage volume. A system along the lines of Figure 3 could be created with minimal upfront costs (on the order of $1,000-$5,000, though further research is needed to derive a concrete estimate). Serving this application for internal use only would require very low ongoing costs after the initial outlay. However, if our intention is to serve this model to the full mc.org audience, costs will rise substantially. Due to the distinct cost and engineering profiles of these options\'97an in-house vs. public RAG/LLM system\'97we recommend considering each option as a fully distinct AI project.\
\pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b \cf0 6.3.2  A Digital Forensics Kit to Support Presidential Recordings Scholarship\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0 \cf0 Current-generation audio-to-text AI is sufficiently powerful to handle tasks like transcribing Miller Center public events and extracting text from PRP recordings to support search engine indexing. But even modern AI has important limitations when it comes to the research problems faced by PRP scholars. First, current models cannot identify who is speaking during an audio recording. Secondly, audio-to-text technology cannot accurately transcribe passages where aging media or recording artifacts render the audio itself noisy. Because of these limitations, AI applications for PRP will have to look beyond off-the-shelf offerings. \
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 Instead of using AI to replace the transcriptive work of scholars, a more feasible approach is to use AI to give scholars new tools that might help them work more efficiently or effectively. In this section we propose two innovations that PRP scholars could use to arrive at forensic insights into the contents audio recordings.\
To help scholars identify speakers, a plausible path forward is to fine tune an audio classification model. Models of this kind take an audio clip as input and return text as their output. In this case we could begin with a foundation model trained to understand recordings of English language conversations. To align this model with PRP needs, we would fine tune it by presenting it with a training collection of labeled audio clips as in Figure 4. The left portion of Figure 4 schematizes the training corpus. This would consist of \{
\f2\i audio clip, speaker name
\f1\i0 \} pairs. This training data would allow the model to learn what JFK\'92s voice (or LBJ\'92s voice, or J. Edgar Hoover\'92s voice) sounds like,. To use the fine-tuned model, PRP scholars would indicate that they would like an assessment of who is speaking at a particular time code in a particular audio file. The model would return a ranked list of possible speakers for the clip in question, along with the probability that each speaker is the correct label. \
\pard\pardeftab720\fi360\sb240\qc\partightenfactor0
\cf0  \
\pard\pardeftab720\sb120\sa120\qc\partightenfactor0
\cf0  \
\pard\pardeftab720\sb120\sa120\partightenfactor0
\cf0 Figure 4: Training and query regime for a speaker identification tool.\
\pard\pardeftab720\fi360\sb240\qj\partightenfactor0
\cf0 A similar tool could help PRP scholars with another common hurdle in their work, transcribing passages that are inaudible. The original White House recordings are often noisy, and in many cases it is difficult to make out how a conversation goes. To help scholars fill in these blanks, a combination of LLMs and audio models could be brought to bear. The idea is that scholars would present to a model the parts of the conversation they 
\f2\i do
\f1\i0  know, and an indication of the part they cannot make out. Based on the given context, the model would return a ranked list of probable transcriptions for the inaudible portion. For instance, if scholars had transcribed a sentence as 
\f2\i Apparently some \{unclear\} in Justice is lobbying with the Post
\f1\i0 , an LLM could induce a probability distribution over all words 
\f2\i X
\f1\i0  in the English language 
\f2\i P
\f1\i0 (
\f2\i X
\f1\i0 | Apparently some \{unclear\}, \{unclear\} in justice is lobbying with the post ).\
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 The training data for both of these tasks is readily available. For the speaker identification task, training data could come from two sources: \
\pard\tx283\pardeftab720\li600\fi-300\sb50\sa120\partightenfactor0
\cf0 \'95	PRP maintains a voice ID bank, a database of sound files, each of which is labeled with the name of the person who is heard speaking in the audio. \
\'95	\'93scroller" presentations on mc.org: each of these multimedia documents contains an audio file and time-coded lists of who is speaking at each moment of the audio. \
\pard\pardeftab720\sb60\qj\partightenfactor0
\cf0 Together these two data sources could train a model to make a judgment of who is speaking in a new, unlabeled recording.\
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 For a system that suggests transcriptions of noisy audio passages, an off-the-shelf foundation LLM might suffice. A fine-tuned model might improve over the foundation model. But the core point in this case is that this task\'97filling in gaps in English language text\'97is precisely how LLMs operate. An LLM is trained by showing it terabytes of text. At each step in the training process, random words in the training text are \'93masked" (hidden). The model is trained by teaching it to guess correctly which words should go into those masked slots. This is precisely the task we would ask the model to do in the PRP case, though here the gaps may contain longer passages than a single word. Nevertheless, the setup is identical.\
It is important to stress that these two applications for PRP would constitute novel research in their own right. It seems plausible and likely that these systems could be trained to deliver predictions that would give PRP scholars a useful new perspective on their work. However, to bring these models up to a useful level of accuracy will require non-trivial scientific (not just engineering) thinking. This would be an exciting, impactful project that would be of scientific interest to the AI community, in addition to its value as a tool to advance PRP scholarship.\
\pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b \cf0 6.3.3  Fine-Tuned LLMs to Create Oral History Interview and PRP Recording Metadata\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0 \cf0 The Miller Center\'92s Presidential Oral History Project (POHP) generates rich interviews with former White House personnel and other presidential confidants. To maximize the value of the corpus of these interviews, two summary bits of metadata are desirable: \
\pard\tx283\pardeftab720\li600\fi-300\sb50\sa120\partightenfactor0
\cf0 1.	
\f2\i Page-wise indexing
\f1\i0 : POHP staff have long desired a full index of all published OHP interviews to support internal organization and retrieval operations. \
2.	
\f2\i Interview-wise summarization
\f1\i0 : When interviews are published, they require an accompanying pr\'e9cis, a brief prose description of the interview contents. \
\pard\pardeftab720\sb60\qj\partightenfactor0
\cf0 Both of these operations\'97indexing interviews and summarizing them into a pr\'e9cis\'97are laborious tasks for humans, but plausibly something an LLM could automate.\
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 Again, the exact design specification for this task\'92s solution is a complex question. But a likely architecture would use LLM fine-tuning. The most direct path towards automating the creation of both OHP metadata types (indexing and pr\'e9cis), would be to choose a foundation model such as GPT-4 and then to fine tune it twice, once for each task, page indexing and interview pr\'e9cis creation. Training two separate models is desirable in this case because we are training for two distinct tasks. Separating the fine tuning process would prevent the model from confusing the two tasks, possibly diminishing the needed volume of training data. \
To train an OHP interview indexing model, the training data would consist of \{interview page, indexing metadata\} pairs. That is, for each training page, humans would enumerate which indexing terms they would assign to that page. Feeding 50-100 indexed pages to the foundation model should give it enough information to generalize well on unseen pages (the real number needed may be substantially lower than 50, as initial experiments suggest that even GPT-4 with no fine tuning performs well on this task.)\
\pard\pardeftab720\fi360\sb240\qc\partightenfactor0
\cf0  \
\pard\pardeftab720\qc\partightenfactor0
\cf0 [Sorry. Ignored 
\f3 \\begin\{lstlisting\} ... \\end\{lstlisting\}
\f1 ]\
\pard\pardeftab720\sb120\sa120\partightenfactor0
\cf0 Figure 5: A sample python program for automatically extracting indexing terms from an OHP interview.\
\pard\pardeftab720\fi360\sb240\qj\partightenfactor0
\cf0 To show how the indexing process could be fully automated, Figure 5 shows a simple program that generates page-wise indexing terms for an Oral History interview. This example gets its data from the GPT-4 foundation model but changing this to pull from a fine-tuned model is trivial (simply change line 12 of the program). By hosting this program in the Miller Center\'92s AWS cloud we could create a system that automatically indexes any new interviews that we publish on mc.org (or that we otherwise mark as \'93complete").\
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 Creating interview pr\'e9cis documents could be automated in a similar way. In this case, instead of training our model in a page-wise fashion, our training data would entail a set of \{interview, precis\} pairs. By using the set of interviews on mc.org that already have a pr\'e9cis, we can build our training set trivially. To train our pr\'e9cis model, we simply upload this training set to the fine-tuning API. The available set of interview-pr\'e9cis pairs should more than suffice for this training.\
There is, however, one point of difficulty that we must solve before deploying an automatic pr\'e9cis creation tool. The problem has to do with the \'93context window" of LLMs. The context window is the maximum allowable length of an LLM\'92s prompts. Each model\'92s context window is different, and for the most part, larger models have larger context windows. GPT-4\'92s context window is 8,000 tokens (approximately 8,000 words). For comparison, the Elliott Abrams interview shown in Figure 5 is 95,693 tokens, as per OpenAI\'92s counting method. Thus we must devise a way to extract a single, summative pr\'e9cis from GPT-4 (or any fine-tuned model derived from it), when we can only show  of the interview to the model at a time.\
How to overcome the context window limitation is a research question in its own right. However, our initial experiments suggest that an iterative algorithm can be used to solve this issue. The algorithm runs as follows: \
\pard\tx283\pardeftab720\li600\fi-300\sb50\sa120\partightenfactor0
\cf0 1.	Begin with input interview document 
\f2\i D
\f1\i0 . \
2.	Split 
\f2\i D
\f1\i0  into 
\f2\i n
\f1\i0  sub-documents  such that for each sub-document  . \
3.	For each sub-document  generate a corresponding \'93pseudo pr\'e9cis"  by submitting  for summarization by the model. This results in a set of 
\f2\i n
\f1\i0  pseudo-pr\'e9cis . \
4.	Generate a final pr\'e9cis 
\f2\i P
\f1\i0  by submitting the set of 
\f2\i n
\f1\i0  pseudo-pr\'e9cis to the model with a prompt asking the model to combine them into a single, unified summary. \
\pard\pardeftab720\sb60\qj\partightenfactor0
\cf0 Testing and troubleshooting this algorithm will require work, but initial experiments suggest that it is feasible and practical. By applying this algorithm, we should be able to obtain coherent summaries for OHP interviews.\
\pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b\fs32 \cf0 6.4  Hazards Associated with AI\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 The opportunities that AI affords the Miller Center are easy to see. The projects we have outlined in this section would bring new efficiencies to Miller Center work, and they are likely to help scholars make novel insights in their research. Some deployments would greatly enhance the experience of visitors to our flagship website. But adopting AI also brings risks for the Miller Center. These risks fall into three main types: \
\pard\tx283\pardeftab720\li600\fi-300\sb50\sa120\partightenfactor0
\cf0 1.	
\f2\i Financial:
\f1\i0  Implementing some of the systems described in this white paper will require significant outlays of money. In particular, deploying an AI model publicly could require steep investment. The good news on this count, however, is that these costs are predictable; we will always know where the financial pinch points are and can monitor them carefully. Also, like all technology, the cost of AI infrastructure is sure to drop in the coming years, mitigating some of this risk. \
2.	
\f2\i Internal:
\f1\i0  Integrating AI into office and scholarly workflows brings some risk of introducing errors or other quality degradations. For AI to work effectively, relevant staff must be instructed on best practices and risk mitigation. Likewise, managers must be circumspect in recommending AI as a solution to work problems. For instance, a controlled study found that creative office tasks often benefit from AI input, while AI can negatively impact the quality of output on rote, administrative tasks [Candelon et\'a0 al., 2023]. \
3.	
\f2\i Outward:
\f1\i0  If the Miller Center were to make a public-facing AI agent (e.g. deploying its Miller Center LLM on the open internet via mc.org), the results are unpredictable. RAG systems are prone to fewer \'93hallucinations\'94 than pure LLMs are, but even RAG systems can give bad answers, and even with guardrails in place, AI systems can be coaxed to generate toxic content. Deploying an AI agent for the public could be helpful and impactful, but the risks of a public deployment are substantial. \
\pard\pardeftab720\sb60\qj\partightenfactor0
\cf0 These are the most obvious risks that the Miller Center would face in the context of formulating an AI strategy. But in the background, more fundamental concerns about AI are also present. Ongoing research in the AI community points to developers\'92 concerns about fairness, bias and toxicity in AI [Cheatham et\'a0 al., 2019, Hendrycks et\'a0 al., 2023]. Because these models rely on vast troves of training data, and because that data must, by virtue of its scale, come from the internet, we know that LLMs have been trained on content that is offensive and factually wrong. How to prevent models from letting toxic content color their output is a crucial and ongoing area of research. \
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 AI\'92s hazards are real. But for the most part they are controllable and avoidable. So long as decision makers and developers build caution and supervision into their plans, AI\'92s benefits are likely to outweigh its risks.\
\pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b\fs32 \cf0 6.5  Recommendations for Choosing AI Projects\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 This section has outlined a large number of complex projects. To help readers gain a sense of how these diverse recommendations could form a coherent plan for adopting AI at the Miller Center, this section suggests an iterative way to explore AI\'92s benefits while also minding its risks. Our goal here is to give a 
\f2\i possible
\f1\i0  path forward. Miller Center leadership will of course make its own determination on this account. \
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 To manage the risks and costs of AI, a simple approach would tackle this problem incrementally, starting with a few simple projects and using the lessons learned from them to bootstrap our way towards more ambitious outcomes.\
For instance, we might start with one of the less risky, yet still ambitious projects from Section 6.3. The two metadata generation tasks we discussed (generating summaries and indexes for OHP interviews and PRP recordings) would be highly valuable. They would also give Miller Center technical staff invaluable practice writing software using AI APIs for production. Most crucially, these projects are also eminently tractable. They would not be easy to complete, but they would provide a clear path to success. This combination of traits\'97high-impact, instructive with respect to future work, and clearly tractable\'97makes these projects ideal choices for a first round of AI work.\
Developing a Miller Center LLM/RAG system would be a logical second step. This task would also be high-impact and tractable, so it could be our first AI project. But the complexity visible in Figure 3 argues for tackling this project after we have gathered some experience with deploying AI applications into the Miller Center\'92s production tech portfolio. \
Among our proposed projects, the heaviest lift from a technical standpoint will be the forensic toolkit for PRP scholars. Developing models that will help scholars label speakers and disambiguate transcriptions will involve getting deep into model architecture. These projects have a clear endpoint. But there is some ambiguity about how to reach that end, ambiguity that will require a research outlook. For this reason, it seems sensible to take on these tasks once we have a solid base of deployments behind us.\
Throughout this three-step iteration, we could simultaneously undertake the easier projects outlined in Section 6.2: mc.org search improvement, expanding {\field{\*\fldinst{HYPERLINK "https://data.millercenter.org"}}{\fldrslt 
\f3 data.millercenter.org}}, and helping staff incorporate AI into their daily work. These projects are by no means trivial. But they will require fewer hours of technical work to accomplish, while also giving staff invaluable experience in writing software using AI APIs. For this reason, it makes sense to complete them in parallel with the more ambitious work of Section 6.3.\
After these projects are complete, it is likely that the Miller Center will continue with future AI work. As we mentioned in Section 4.7, this white paper has largely omitted consideration of our binary data resources. In future work, it would make sense to focus on assets like our past event videos. Current-generation AI is most adept at dealing with text. But recent advances in multimodal AI suggest that researchers are working to bring video, images, and audio into first-class AI citizenship. For now, however, we recommend an iterative, text-based approach along the lines of what we outlined in this section.\
\pard\pardeftab720\sb240\sa120\partightenfactor0

\f0\b\fs32 \cf0 7  Conclusion\
\pard\pardeftab720\sb60\qj\partightenfactor0

\f1\b0\fs24 \cf0 The Miller Center is poised to use AI technologies in ways that deepen its already first-rate scholarship. Innovations such as LLM-based pr\'e9cis generation for OHP interviews, forensic audio analysis for PRP transcription, and a Miller Center LLM/RAG system would allow scholars to approach familiar research activities from a new perspective. On the other hand, less lofty applications\'97bringing AI into staff\'92s daily office work and using AI to improve mc.org site search\'97constitute clear steps towards enhancing the Miller Center\'92s institutional outreach and internal efficiency. Collectively, these options give the Miller Center a spectrum of tangible ways to initiate a bold technical and intellectual move by adopting AI.\
\pard\pardeftab720\fi360\qj\partightenfactor0
\cf0 If the Miller Center chooses to move forward with a slate of AI projects, some of the resultant benefits are easy to predict. At the most transactional level, AI has been shown to improve office productivity [Candelon et\'a0 al., 2023], and the Miller Center is likely to find tangible benefits from bringing AI into its everyday work. But more exciting advances are also likely to follow from a strategic adoption of AI. The Miller Center possesses a unique portfolio of data, and AI would give us an apparatus for using these data in truly novel ways. Lastly, several of the AI projects proposed in Section 6.3 would help advance the state of the art in AI, constituting original research. As leadership considers a future for AI at the Miller Center, balancing these (and possibly additional, unknown) benefits with the risks and costs described in Section 6 with be of paramount importance.\
The goal of this white paper has been to give leadership the tools it needs to strike the balance between AI\'92s risks and rewards. We grounded our discussion by offering a set of crucial definitions and a shared vocabulary in Section 3. Our data census in Section 4 outlined the extent, formats, and ownership details of our data holdings. In Section 5 we outlined the most vital AI initiatives currently and recently underway at UVA, taking pains to show how the Miller Center fits into the AI landscape on Grounds. Finally, Section 6 details seven \'93shovel-ready" AI projects the Miller Center could undertake, each of which balances AI\'92s risks and rewards differently, delivering a unique spectrum of value propositions. Novel semantic technologies such as LLMs and multimodal deep learning have made data valuable in a qualitatively new way. Organizations can use data (and models trained from data) to make insights and efficiencies that were out of reach only a few years ago. Given its unique data portfolio, its scholarly position vis-\'e0-vis that data, and its in-house technical resources, the Miller Center is in a position to use AI in ways that substantially increase the reach and impact of its work. \
\page \pard\pardeftab720\sb120\sa120\partightenfactor0

\f0\b\fs32 \cf0 References\
\pard\pardeftab720\li450\sb60\partightenfactor0

\f1\b0\fs20 \cf0 [Brown et\'a0 al., 2020]	Brown, T.\'a0B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D.\'a0M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., and Amodei, D. (2020). Language models are few-shot learners. 
\f2\i arxiv
\f1\i0 , {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/2005.14165"}}{\fldrslt 
\f3 https://arxiv.org/abs/2005.14165}}.\
\pard\pardeftab720\li450\partightenfactor0
\cf0 [Candelon et\'a0 al., 2023]	Candelon, F., Krayer, L., Rajendran, S., and Martinez, D.\'a0Z. (2023). How People can Create\'96and Destroy\'96Value with Generative AI. 
\f2\i BCG Henderson Institute
\f1\i0 , {\field{\*\fldinst{HYPERLINK "https://www.bcg.com/publications/2023/how-people-create-and-destroy-value-with-gen-ai"}}{\fldrslt 
\f3 https://www.bcg.com/publications/2023/how-people-create-and-destroy-value-with-gen-ai}}.\
[Cheatham et\'a0 al., 2019]	Cheatham, B., Javanmardian, K., and Samandari, H. (2019). Confronting the risks of artificial intelligence. 
\f2\i McKinsey Quarterly
\f1\i0 , 2(38): 1\'969.\
[Dodge et\'a0 al., 2021]	Dodge, J., Sap, M., Marasovi\uc0\u263 , A., Agnew, W., Ilharco, G., Groeneveld, D., Mitchell, M., and Gardner, M. (2021). Documenting large webtext corpora: A case study on the colossal clean crawled corpus. 
\f2\i arxiv
\f1\i0 , {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/2104.08758"}}{\fldrslt 
\f3 https://arxiv.org/abs/2104.08758}}.\
[Gao et\'a0 al., 2020]	Gao, L., Biderman, S., Black, S., Golding, L., Hoppe, T., Foster, C., Phang, J., He, H., Thite, A., Nabeshima, N., Presser, S., and Leahy, C. (2020). The Pile: An 800GB dataset of diverse text for language modeling. 
\f2\i arXiv preprint arXiv:2101.00027
\f1\i0 , {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/2101.00027"}}{\fldrslt 
\f3 https://arxiv.org/abs/2101.00027}}.\
[Hendrycks et\'a0 al., 2023]	Hendrycks, D., Mazeika, M., and Woodside, T. (2023). An Overview of Catastrophic AI Risks. 
\f2\i arxiv
\f1\i0 , {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/2306.12001"}}{\fldrslt 
\f3 https://arxiv.org/abs/2306.12001}}.\
[Javaness, 2023]	Javaness, L. (2023). LLM Large Language Model Cost Analysis. 
\f2\i Towards Data Science
\f1\i0 , {\field{\*\fldinst{HYPERLINK "https://lajavaness.medium.com/llm-large-language-model-cost-analysis-d5022bb43e9e"}}{\fldrslt 
\f3 https://lajavaness.medium.com/llm-large-language-model-cost-analysis-d5022bb43e9e}}.\
[Liu et\'a0 al., 2022]	Liu, H., Tam, D., Muqeeth, M., Mohta, J., Huang, T., Bansal, M., and Raffel, C. (2022). Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning. 
\f2\i arxiv
\f1\i0 , {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/2205.05638"}}{\fldrslt 
\f3 https://arxiv.org/abs/2205.05638}}.\
[Shazeer et\'a0 al., 2017]	Shazeer, N., Mirhoseini, A., Maziarz, K., Davis, A., Le, Q., Hinton, G., and Dean, J. (2017). Outrageously large neural networks: The sparsely-gated mixture-of-experts layer. 
\f2\i arxiv
\f1\i0 , {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/1701.06538"}}{\fldrslt 
\f3 https://arxiv.org/abs/1701.06538}}.\
[Vivek, 2023]	Vivek, S. (2023). LLM Economics: ChatGPT vs Open-Source. 
\f2\i Towards Data Science
\f1\i0 , {\field{\*\fldinst{HYPERLINK "https://towardsdatascience.com/llm-economics-chatgpt-vs-open-source-dfc29f69fec1"}}{\fldrslt 
\f3 https://towardsdatascience.com/llm-economics-chatgpt-vs-open-source-dfc29f69fec1}}.\
[Wei et\'a0 al., 2022]	Wei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D., Metzler, D., Chi, E.\'a0H., Hashimoto, T., Vinyals, O., Liang, P., Dean, J., and Fedus, W. (2022). Emergent abilities of large language models. 
\f2\i Transactions on Machine Learning Research
\f1\i0 . Survey Certification.\
[White et\'a0 al., 2023]	White, J., Fu, Q., Hays, S., Sandborn, M., Olea, C., Gilbert, H., Elnashar, A., Spencer-Smith, J., and Schmidt, D.\'a0C. (2023). A prompt pattern catalog to enhance prompt engineering with ChatGPT. 
\f2\i arxiv
\f1\i0 , {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/2302.11382"}}{\fldrslt 
\f3 https://arxiv.org/abs/2302.11382}}.\
}